{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2a21598",
      "metadata": {
        "id": "b2a21598"
      },
      "source": [
        "# WEEK 37\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50500cb8",
      "metadata": {
        "id": "50500cb8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Iterable\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import MLE, Laplace, KneserNeyInterpolated,  WittenBellInterpolated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d4cdd5a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cdd5a3",
        "outputId": "d298095d-bb69-4037-b32b-82875ac07c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            question  \\\n",
            "0  উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...   \n",
            "1           দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?   \n",
            "2  মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...   \n",
            "3  আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...   \n",
            "4          বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  WikiLeaks () is an international non-profit or...   bn        True   \n",
            "1  The war in Europe concluded with an invasion o...   bn        True   \n",
            "2  Same-sex marriage in the United States expande...   bn       False   \n",
            "3  The exact number of Arab casualties is unknown...   bn        True   \n",
            "4  As Thomas Hall (2000) notes, \"The Sung Empire ...   bn        True   \n",
            "\n",
            "   answer_start        answer answer_inlang  \n",
            "0           182          2006          None  \n",
            "1            48       Germany          None  \n",
            "2            -1            no          None  \n",
            "3            39       unknown          None  \n",
            "4          1219  17th century          None  \n",
            "                                      question  \\\n",
            "0     ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది ?   \n",
            "1  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "2  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "3      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "4      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  Portland is the largest city in the U.S. state...   te        True   \n",
            "1  The word cholera is from \"kholera\" from χολή \"...   te        True   \n",
            "2  Since it became widespread in the 19th century...   te        True   \n",
            "3  World War I occurred from 1914 to 1918. In ter...   te        True   \n",
            "4  World War I (often abbreviated as WWI or WW1),...   te        True   \n",
            "\n",
            "   answer_start               answer answer_inlang  \n",
            "0             0             Portland          None  \n",
            "1            99  Indian subcontinent          None  \n",
            "2           451              England          None  \n",
            "3            26                 1914          None  \n",
            "4           155         28 July 1914          None  \n"
          ]
        }
      ],
      "source": [
        "## K = 3\n",
        "\n",
        "#DOWNLOAD DATASET\n",
        "\n",
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "print(df_train.head())\n",
        "print(df_val.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "407e07b7",
      "metadata": {
        "id": "407e07b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "QUESTION_FIELD = \"question\"\n",
        "\n",
        "CONTEXT_FIELD = \"context\"\n",
        "\n",
        "LANG_FIELD = \"lang\"\n",
        "\n",
        "LANGUAGES = [\"ar\", \"ko\", \"te\", \"en\"]\n",
        "\n",
        "N_ORDERS = [2, 3]\n",
        "\n",
        "MIN_FREQ = 3\n",
        "\n",
        "SMOOTHINGS= [\"laplace\", \"kn\", \"wb\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fa5a94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fa5a94",
        "outputId": "946fd48f-d988-4091-ef19-696f71de88f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # ne\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize      # Arabic\n",
        "from konlpy.tag import Okt                                        # Korean\n",
        "from indicnlp.tokenize import indic_tokenize                      # Telugu\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def get_tokenizer(lang: str):\n",
        "    if lang == \"en\":\n",
        "        return nltk.word_tokenize\n",
        "    elif lang == \"ar\":\n",
        "        return simple_word_tokenize\n",
        "    elif lang == \"ko\":\n",
        "        return okt.morphs\n",
        "    elif lang == \"te\":\n",
        "        return lambda text: list(indic_tokenize.trivial_tokenize(text))\n",
        "    else:\n",
        "        # fallback: split on words\n",
        "        return nltk.word_tokenize\n",
        "\n",
        "def tokenize_column(series, lang: str):\n",
        "    tokenizer = get_tokenizer(lang)\n",
        "    out = []\n",
        "    for x in series:\n",
        "        if not isinstance(x, str):\n",
        "            x = \"\" if x is None else str(x)\n",
        "        x = x.lower()\n",
        "        out.append(tokenizer(x))\n",
        "    return out\n",
        "\n",
        "def build_vocab(tokenized: List[List[str]], min_freq: int = 1) -> Dict[str, int]:\n",
        "    cnt = Counter(w for s in tokenized for w in s)\n",
        "    vocab = {w: i for i, (w, c) in enumerate(cnt.items()) if c >= min_freq}\n",
        "    vocab[\"<OOV>\"] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def apply_oov(tokenized: List[List[str]], vocab: Dict[str, int]) -> List[List[str]]:\n",
        "    return [[w if w in vocab else \"<OOV>\" for w in s] for s in tokenized]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "79dd61f9",
      "metadata": {
        "id": "79dd61f9"
      },
      "outputs": [],
      "source": [
        "def train_lm(tokenized: List[List[str]], order: int = 2, smoothing: str = \"laplace\"):\n",
        "    smoothing = (smoothing or \"\").lower()\n",
        "    if smoothing in {\"\", \"mle\"}:\n",
        "        model = MLE(order)\n",
        "    elif smoothing in {\"laplace\", \"addone\", \"add-one\"}:\n",
        "        model = Laplace(order)\n",
        "    elif smoothing in {\"kn\", \"kneserney\", \"kneser-ney\"}:\n",
        "        model = KneserNeyInterpolated(order)\n",
        "    elif smoothing in {\"wb\"}:\n",
        "        model = WittenBellInterpolated(order)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported smoothing: {smoothing}\")\n",
        "\n",
        "    train_data, vocab = padded_everygram_pipeline(order, tokenized)\n",
        "\n",
        "    model.fit(train_data, vocab)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c5da10df",
      "metadata": {
        "id": "c5da10df"
      },
      "outputs": [],
      "source": [
        "def corpus_perplexity(model, tokenized: List[List[str]], order: int) -> dict:\n",
        "    total_logp = 0.0\n",
        "    total_count = 0\n",
        "    for sent in tokenized:\n",
        "        padded = list(pad_both_ends(sent, n=order))\n",
        "        for ng in ngrams(padded, order):\n",
        "            ctx = ng[:-1]\n",
        "            w   = ng[-1]\n",
        "            p = model.score(w, ctx)\n",
        "            if p <= 0.0:\n",
        "                p = 1e-12  # guard\n",
        "            total_logp += math.log(p)\n",
        "            total_count += 1\n",
        "    ce  = - total_logp / max(total_count, 1) # cross-entropy\n",
        "    ppl = math.exp(ce) # perplexity\n",
        "    return {\"cross_entropy\": ce, \"perplexity\": ppl, \"tokens_counted\": total_count}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5509924d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "5509924d",
        "outputId": "6714fc4b-fa92-46fd-d375-84d187288a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Language: ar , train=2558 , valid=415\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenize_column' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-162923285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtr_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mva_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenize_column' is not defined"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    # pick the text columns\n",
        "    if lang == \"en\":\n",
        "        tr_series = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        # exclude KN for English\n",
        "        smoothings_here = [s for s in SMOOTHINGS\n",
        "                           if s.lower() not in {\"kn\"}]\n",
        "    else:\n",
        "        tr_series = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        # use all listed smoothings\n",
        "        smoothings_here = SMOOTHINGS[:]\n",
        "\n",
        "    print(f\"\\n Language: {lang} | train={len(tr_series)} | valid={len(va_series)}\")\n",
        "\n",
        "    # tokenize\n",
        "    tr_tok = tokenize_column(tr_series, lang)\n",
        "    va_tok = tokenize_column(va_series, lang)\n",
        "\n",
        "    # Build vocabulary from training tokens then map OOV to <UNK>\n",
        "    vocab     = build_vocab(tr_tok, min_freq=MIN_FREQ)\n",
        "    tr_tok_u  = apply_oov(tr_tok, vocab)\n",
        "    va_tok_u  = apply_oov(va_tok, vocab)\n",
        "\n",
        "    # Train and evaluate n-gram LMs\n",
        "    for n in N_ORDERS:\n",
        "        for s in smoothings_here:\n",
        "            lm = train_lm(tr_tok_u, order=n, smoothing=s)\n",
        "            metrics = corpus_perplexity(lm, va_tok_u, order=n)\n",
        "            results.append({\n",
        "                \"language\": lang,\n",
        "                \"vocab_size\" : len(vocab),\n",
        "                \"order\": n,\n",
        "                \"smoothing\": s,\n",
        "                **metrics\n",
        "            })\n",
        "            print(f\"n={n} {s}: PPL={round(metrics['perplexity'],2)} CE={round(metrics['cross_entropy'],4)} tokens={metrics['tokens_counted']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3cfccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "2c3cfccd",
        "outputId": "2f78d299-3e19-468b-e1eb-b3e421af2e43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"en\",\n          \"te\",\n          \"ar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocab_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11207,\n        \"min\": 479,\n        \"max\": 29119,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          29119,\n          479,\n          965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoothing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"laplace\",\n          \"kn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cross_entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7914186005531387,\n        \"min\": 1.9854291586476187,\n        \"max\": 8.995849456524624,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.5428075501976486,\n          3.903741618527157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1727.1523733177587,\n        \"min\": 7.282171921998289,\n        \"max\": 8069.521424944306,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          34.5638227638145,\n          49.58764046605111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_counted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138719,\n        \"min\": 3074,\n        \"max\": 356466,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3872,\n          3964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "res_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b1839352-5c94-4ea7-97b6-cc3597ec0749\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>vocab_size</th>\n",
              "      <th>order</th>\n",
              "      <th>smoothing</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>tokens_counted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.542808</td>\n",
              "      <td>34.563823</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.582526</td>\n",
              "      <td>13.230522</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.551880</td>\n",
              "      <td>12.831205</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>4.002280</td>\n",
              "      <td>54.722794</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.487780</td>\n",
              "      <td>12.034535</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.280074</td>\n",
              "      <td>9.777403</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>7.319152</td>\n",
              "      <td>1508.923553</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>5.346028</td>\n",
              "      <td>209.773333</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>8.995849</td>\n",
              "      <td>8069.521425</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>4.988482</td>\n",
              "      <td>146.713584</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.414756</td>\n",
              "      <td>30.409543</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.475640</td>\n",
              "      <td>11.889310</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.442945</td>\n",
              "      <td>11.506884</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.903742</td>\n",
              "      <td>49.587640</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.272751</td>\n",
              "      <td>9.706070</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.099194</td>\n",
              "      <td>8.159591</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.421393</td>\n",
              "      <td>30.612033</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.396618</td>\n",
              "      <td>10.985954</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.387861</td>\n",
              "      <td>10.890179</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.774726</td>\n",
              "      <td>43.585584</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.144345</td>\n",
              "      <td>8.536447</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>1.985429</td>\n",
              "      <td>7.282172</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1839352-5c94-4ea7-97b6-cc3597ec0749')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dec13ff1-0510-4567-a203-b01b7e197824\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dec13ff1-0510-4567-a203-b01b7e197824')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dec13ff1-0510-4567-a203-b01b7e197824 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   language  vocab_size  order smoothing  cross_entropy   perplexity  \\\n",
              "0        ar         965      2   laplace       3.542808    34.563823   \n",
              "1        ar         965      2        kn       2.582526    13.230522   \n",
              "2        ar         965      2        wb       2.551880    12.831205   \n",
              "3        ar         965      3   laplace       4.002280    54.722794   \n",
              "4        ar         965      3        kn       2.487780    12.034535   \n",
              "5        ar         965      3        wb       2.280074     9.777403   \n",
              "18       en       29119      2   laplace       7.319152  1508.923553   \n",
              "19       en       29119      2        wb       5.346028   209.773333   \n",
              "20       en       29119      3   laplace       8.995849  8069.521425   \n",
              "21       en       29119      3        wb       4.988482   146.713584   \n",
              "6        ko         755      2   laplace       3.414756    30.409543   \n",
              "7        ko         755      2        kn       2.475640    11.889310   \n",
              "8        ko         755      2        wb       2.442945    11.506884   \n",
              "9        ko         755      3   laplace       3.903742    49.587640   \n",
              "10       ko         755      3        kn       2.272751     9.706070   \n",
              "11       ko         755      3        wb       2.099194     8.159591   \n",
              "12       te         479      2   laplace       3.421393    30.612033   \n",
              "13       te         479      2        kn       2.396618    10.985954   \n",
              "14       te         479      2        wb       2.387861    10.890179   \n",
              "15       te         479      3   laplace       3.774726    43.585584   \n",
              "16       te         479      3        kn       2.144345     8.536447   \n",
              "17       te         479      3        wb       1.985429     7.282172   \n",
              "\n",
              "    tokens_counted  \n",
              "0             3457  \n",
              "1             3457  \n",
              "2             3457  \n",
              "3             3872  \n",
              "4             3872  \n",
              "5             3872  \n",
              "18          353455  \n",
              "19          353455  \n",
              "20          356466  \n",
              "21          356466  \n",
              "6             3608  \n",
              "7             3608  \n",
              "8             3608  \n",
              "9             3964  \n",
              "10            3964  \n",
              "11            3964  \n",
              "12            3074  \n",
              "13            3074  \n",
              "14            3074  \n",
              "15            3458  \n",
              "16            3458  \n",
              "17            3458  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_df = pd.DataFrame(results).sort_values([\"language\",\"order\"])\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PqNPCPGv9sms",
      "metadata": {
        "id": "PqNPCPGv9sms"
      },
      "source": [
        "### POTENTIAL NEURAL MODEL ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CqYMZhk7KRw7",
      "metadata": {
        "id": "CqYMZhk7KRw7"
      },
      "outputs": [],
      "source": [
        "# If needed (Colab/new env), uncomment:\n",
        "# !pip install -q bpemb torch\n",
        "\n",
        "import math, re, random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from bpemb import BPEmb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n980Tf6kS6_0",
      "metadata": {
        "id": "n980Tf6kS6_0"
      },
      "outputs": [],
      "source": [
        "SEED      = 42\n",
        "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# training knobs (start small, bump after it works)\n",
        "EPOCHS    = 10\n",
        "BATCH     = 128\n",
        "SEQ_LEN   = 120\n",
        "EMB_DIM   = 100\n",
        "HIDDEN    = 256\n",
        "LAYERS    = 2\n",
        "DROPOUT   = 0.2\n",
        "LR        = 2e-3\n",
        "CLIP      = 1.0\n",
        "\n",
        "# bpemb options\n",
        "# ar/ko/te/en separately\n",
        "BPE_PER_LANGUAGE = True\n",
        "BP_VS   = 5000    # vocab size\n",
        "BP_DIM  = EMB_DIM   # should equal EMB_DIM\n",
        "\n",
        "# light text normalization\n",
        "LOWERCASE    = True\n",
        "FOLD_NUMBERS = True\n",
        "\n",
        "# throttle English contexts (they’re huge)\n",
        "EN_MAX_ROWS_TRAIN    = 30000\n",
        "EN_MAX_ROWS_VALID    = 5000\n",
        "EN_MAX_TOK_PER_DOC   = 400 # subword pieces per doc (for speed)\n",
        "FREEZE_EMBEDDINGS    = True # False = fine-tune embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QZAwr540TOEO",
      "metadata": {
        "id": "QZAwr540TOEO"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-SIaeTdTPuS",
      "metadata": {
        "id": "c-SIaeTdTPuS"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XTdgQlx4TUVo",
      "metadata": {
        "id": "XTdgQlx4TUVo"
      },
      "outputs": [],
      "source": [
        "_bp_cache = {}\n",
        "\n",
        "def load_bpemb_for_lang(lang: str):\n",
        "    if BPE_PER_LANGUAGE:\n",
        "        key = f\"{lang}:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=lang, vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "    else:\n",
        "        key = f\"multi:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=\"multi\", vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "\n",
        "def build_embedding_matrix(bp: BPEmb):\n",
        "    # bp.emb.vectors shape: (vs, dim)\n",
        "    pad_vec = np.zeros((1, BP_DIM), dtype=np.float32)\n",
        "    eos_vec = np.zeros((1, BP_DIM), dtype=np.float32)\n",
        "    mat = np.concatenate([bp.emb.vectors, pad_vec, eos_vec], axis=0).astype(np.float32)\n",
        "    pad_id = bp.emb.vectors.shape[0] # PAD index\n",
        "    eos_id = bp.emb.vectors.shape[0] + 1 # EOS index\n",
        "    return torch.tensor(mat), pad_id, eos_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ISId1NZTXES",
      "metadata": {
        "id": "-ISId1NZTXES"
      },
      "outputs": [],
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d) # list of subword ids\n",
        "        if max_len_per_doc:\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BwPuUPY4TYnR",
      "metadata": {
        "id": "BwPuUPY4TYnR"
      },
      "outputs": [],
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d) # list of subword ids\n",
        "        if max_len_per_doc:\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bw0gFkvaTbJp",
      "metadata": {
        "id": "bw0gFkvaTbJp"
      },
      "outputs": [],
      "source": [
        "class WPLSTMLM(nn.Module):\n",
        "    def __init__(self, emb_matrix: torch.Tensor, pad_id: int, hidden=256, layers=2, dropout=0.2, freeze=True):\n",
        "        super().__init__()\n",
        "        V, D = emb_matrix.shape\n",
        "        self.embed = nn.Embedding.from_pretrained(emb_matrix, freeze=freeze, padding_idx=pad_id)\n",
        "        self.lstm  = nn.LSTM(D, hidden, num_layers=layers, dropout=dropout, batch_first=True)\n",
        "        self.drop  = nn.Dropout(dropout)\n",
        "        self.head  = nn.Linear(hidden, V)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embed(x)\n",
        "        x, h = self.lstm(x, h)\n",
        "        x = self.drop(x)\n",
        "        logits = self.head(x)\n",
        "        return logits, h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AtVVDz0GTe3a",
      "metadata": {
        "id": "AtVVDz0GTe3a"
      },
      "outputs": [],
      "source": [
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_tok = 0.0, 0\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "    for x, y in loader:\n",
        "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "        logits, _ = model(x)\n",
        "        loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "        total_tok  += y.numel()\n",
        "    ce  = total_loss / max(total_tok, 1)\n",
        "    ppl = math.exp(ce)\n",
        "    return ce, ppl, total_tok\n",
        "\n",
        "def train_bpemb_lm(lang, train_series, valid_series, max_tok_per_doc=None):\n",
        "    set_seed()\n",
        "    bp   = load_bpemb_for_lang(lang if BPE_PER_LANGUAGE else \"multi\")\n",
        "    embM, pad_id, eos_id = build_embedding_matrix(bp)\n",
        "\n",
        "    ids_tr = encode_docs_to_stream(bp, list(train_series), eos_id, max_tok_per_doc)\n",
        "    ids_va = encode_docs_to_stream(bp, list(valid_series), eos_id, max_tok_per_doc)\n",
        "\n",
        "    tr_dl, va_dl = make_loaders(ids_tr, ids_va, SEQ_LEN, BATCH)\n",
        "\n",
        "    model = WPLSTMLM(embM, pad_id, hidden=HIDDEN, layers=LAYERS, dropout=DROPOUT, freeze=FREEZE_EMBEDDINGS).to(DEVICE)\n",
        "    opt   = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "\n",
        "    print(f\"[{lang}] subword_vocab={embM.size(0)} train_batches={len(tr_dl)} valid_batches={len(va_dl)} device={DEVICE}\")\n",
        "\n",
        "    best = float(\"inf\")\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total, steps = 0.0, 0\n",
        "        crit = nn.CrossEntropyLoss()\n",
        "        for x, y in tr_dl:\n",
        "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits, _ = model(x)\n",
        "            loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "            opt.step()\n",
        "            total += loss.item(); steps += 1\n",
        "        sched.step()\n",
        "        ce, ppl, tok = evaluate(model, va_dl)\n",
        "        best = min(best, ppl)\n",
        "        print(f\"epoch {str(ep).zfill(2)} train_ce={round(total/max(steps,1),4)} val_ce={round(ce,4)} val_ppl={round(ppl,2)} tokens={tok}\")\n",
        "    return best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MoOHavS7TiN0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoOHavS7TiN0",
        "outputId": "654ece7b-1a88-4b43-ea54-a87ecc3fa78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "▶ BPEmb LSTM on ar: train_rows=2558 valid_rows=415\n",
            "downloading https://nlp.h-its.org/bpemb/ar/ar.wiki.bpe.vs5000.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 327600/327600 [00:00<00:00, 690565.45B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/ar/ar.wiki.bpe.vs5000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1891414/1891414 [00:00<00:00, 2023257.75B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ar] subword_vocab=5002 train_batches=2 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=8.4895  val_ce=8.3945  val_ppl=4422.85  tokens=5520\n",
            "  epoch 02  train_ce=8.2661  val_ce=7.4366  val_ppl=1696.89  tokens=5520\n",
            "  epoch 03  train_ce=7.1892  val_ce=6.6884  val_ppl=803.03  tokens=5520\n",
            "  epoch 04  train_ce=6.5913  val_ce=6.4668  val_ppl=643.40  tokens=5520\n",
            "  epoch 05  train_ce=6.4039  val_ce=6.4193  val_ppl=613.57  tokens=5520\n",
            "  epoch 06  train_ce=6.3435  val_ce=6.4001  val_ppl=601.91  tokens=5520\n",
            "  epoch 07  train_ce=6.3064  val_ce=6.3890  val_ppl=595.29  tokens=5520\n",
            "  epoch 08  train_ce=6.2916  val_ce=6.3832  val_ppl=591.83  tokens=5520\n",
            "  epoch 09  train_ce=6.2834  val_ce=6.3798  val_ppl=589.84  tokens=5520\n",
            "  epoch 10  train_ce=6.2718  val_ce=6.3786  val_ppl=589.12  tokens=5520\n",
            "\n",
            "▶ BPEmb LSTM on ko: train_rows=2422 valid_rows=356\n",
            "downloading https://nlp.h-its.org/bpemb/ko/ko.wiki.bpe.vs5000.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 298782/298782 [00:00<00:00, 634951.68B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/ko/ko.wiki.bpe.vs5000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875484/1875484 [00:00<00:00, 2009551.21B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ko] subword_vocab=5002 train_batches=2 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=8.4980  val_ce=8.3483  val_ppl=4223.04  tokens=6360\n",
            "  epoch 02  train_ce=8.1097  val_ce=7.0354  val_ppl=1136.15  tokens=6360\n",
            "  epoch 03  train_ce=6.7482  val_ce=6.0519  val_ppl=424.93  tokens=6360\n",
            "  epoch 04  train_ce=5.9002  val_ce=5.5998  val_ppl=270.38  tokens=6360\n",
            "  epoch 05  train_ce=5.5192  val_ce=5.4357  val_ppl=229.46  tokens=6360\n",
            "  epoch 06  train_ce=5.3762  val_ce=5.4165  val_ppl=225.09  tokens=6360\n",
            "  epoch 07  train_ce=5.3617  val_ce=5.4164  val_ppl=225.08  tokens=6360\n",
            "  epoch 08  train_ce=5.3457  val_ce=5.4094  val_ppl=223.50  tokens=6360\n",
            "  epoch 09  train_ce=5.3397  val_ce=5.4024  val_ppl=221.95  tokens=6360\n",
            "  epoch 10  train_ce=5.3428  val_ce=5.3999  val_ppl=221.39  tokens=6360\n",
            "\n",
            "▶ BPEmb LSTM on te: train_rows=1355 valid_rows=384\n",
            "downloading https://nlp.h-its.org/bpemb/te/te.wiki.bpe.vs5000.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 348667/348667 [00:00<00:00, 741674.58B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/te/te.wiki.bpe.vs5000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1896297/1896297 [00:00<00:00, 2023109.37B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[te] subword_vocab=5002 train_batches=1 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=8.5142  val_ce=8.4695  val_ppl=4766.94  tokens=4800\n",
            "  epoch 02  train_ce=8.4707  val_ce=8.3996  val_ppl=4445.14  tokens=4800\n",
            "  epoch 03  train_ce=8.3974  val_ce=8.2085  val_ppl=3672.07  tokens=4800\n",
            "  epoch 04  train_ce=8.1985  val_ce=7.6921  val_ppl=2191.04  tokens=4800\n",
            "  epoch 05  train_ce=7.6548  val_ce=7.2525  val_ppl=1411.62  tokens=4800\n",
            "  epoch 06  train_ce=7.1784  val_ce=6.9869  val_ppl=1082.32  tokens=4800\n",
            "  epoch 07  train_ce=6.8820  val_ce=6.8540  val_ppl=947.70  tokens=4800\n",
            "  epoch 08  train_ce=6.7316  val_ce=6.7848  val_ppl=884.27  tokens=4800\n",
            "  epoch 09  train_ce=6.6538  val_ce=6.7536  val_ppl=857.10  tokens=4800\n",
            "  epoch 10  train_ce=6.6274  val_ce=6.7455  val_ppl=850.23  tokens=4800\n",
            "\n",
            "▶ BPEmb LSTM on en: train_rows=15343 valid_rows=3011\n",
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs5000.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315918/315918 [00:00<00:00, 679171.15B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs5000.d100.w2v.bin.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1888515/1888515 [00:00<00:00, 1984814.10B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[en] subword_vocab=5002 train_batches=173 valid_batches=35 device=cuda\n",
            "  epoch 01  train_ce=6.4081  val_ce=5.9306  val_ppl=376.39  tokens=533520\n",
            "  epoch 02  train_ce=5.7721  val_ce=5.5547  val_ppl=258.46  tokens=533520\n",
            "  epoch 03  train_ce=5.4890  val_ce=5.3378  val_ppl=208.06  tokens=533520\n",
            "  epoch 04  train_ce=5.3074  val_ce=5.1824  val_ppl=178.11  tokens=533520\n",
            "  epoch 05  train_ce=5.1819  val_ce=5.0780  val_ppl=160.45  tokens=533520\n",
            "  epoch 06  train_ce=5.0938  val_ce=5.0059  val_ppl=149.29  tokens=533520\n",
            "  epoch 07  train_ce=5.0333  val_ce=4.9567  val_ppl=142.12  tokens=533520\n",
            "  epoch 08  train_ce=4.9940  val_ce=4.9276  val_ppl=138.05  tokens=533520\n",
            "  epoch 09  train_ce=4.9709  val_ce=4.9133  val_ppl=136.09  tokens=533520\n",
            "  epoch 10  train_ce=4.9605  val_ce=4.9092  val_ppl=135.54  tokens=533520\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'language': 'ar', 'model': 'bpemb_lstm', 'best_ppl': 589.1164641212491},\n",
              " {'language': 'ko', 'model': 'bpemb_lstm', 'best_ppl': 221.3915942631238},\n",
              " {'language': 'te', 'model': 'bpemb_lstm', 'best_ppl': 850.2307748852978},\n",
              " {'language': 'en', 'model': 'bpemb_lstm', 'best_ppl': 135.5374765242528}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bpemb_results = []\n",
        "for lang in LANGUAGES:\n",
        "    tr, va, max_len = get_series(lang)\n",
        "    print(f\"\\n BPEmb LSTM on {lang}: train_rows={len(tr)} valid_rows={len(va)}\")\n",
        "    best_ppl = train_bpemb_lm(lang if lang!=\"en\" else \"en\", tr, va, max_tok_per_doc=max_len)\n",
        "    bpemb_results.append({\"language\": lang, \"model\": \"bpemb_lstm\", \"best_ppl\": best_ppl})\n",
        "\n",
        "bpemb_results\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}