{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2a21598",
      "metadata": {
        "id": "b2a21598"
      },
      "source": [
        "# WEEK 37\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "50500cb8",
      "metadata": {
        "id": "50500cb8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Iterable\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import MLE, Laplace, KneserNeyInterpolated,  WittenBellInterpolated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d4cdd5a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cdd5a3",
        "outputId": "41d02ac2-1183-44c2-cd0f-5fd8cf55f9af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            question  \\\n",
            "0  উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...   \n",
            "1           দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?   \n",
            "2  মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...   \n",
            "3  আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...   \n",
            "4          বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  WikiLeaks () is an international non-profit or...   bn        True   \n",
            "1  The war in Europe concluded with an invasion o...   bn        True   \n",
            "2  Same-sex marriage in the United States expande...   bn       False   \n",
            "3  The exact number of Arab casualties is unknown...   bn        True   \n",
            "4  As Thomas Hall (2000) notes, \"The Sung Empire ...   bn        True   \n",
            "\n",
            "   answer_start        answer answer_inlang  \n",
            "0           182          2006          None  \n",
            "1            48       Germany          None  \n",
            "2            -1            no          None  \n",
            "3            39       unknown          None  \n",
            "4          1219  17th century          None  \n",
            "                                      question  \\\n",
            "0     ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది ?   \n",
            "1  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "2  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "3      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "4      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  Portland is the largest city in the U.S. state...   te        True   \n",
            "1  The word cholera is from \"kholera\" from χολή \"...   te        True   \n",
            "2  Since it became widespread in the 19th century...   te        True   \n",
            "3  World War I occurred from 1914 to 1918. In ter...   te        True   \n",
            "4  World War I (often abbreviated as WWI or WW1),...   te        True   \n",
            "\n",
            "   answer_start               answer answer_inlang  \n",
            "0             0             Portland          None  \n",
            "1            99  Indian subcontinent          None  \n",
            "2           451              England          None  \n",
            "3            26                 1914          None  \n",
            "4           155         28 July 1914          None  \n"
          ]
        }
      ],
      "source": [
        "## K = 3\n",
        "\n",
        "#DOWNLOAD DATASET\n",
        "\n",
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "print(df_train.head())\n",
        "print(df_val.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "407e07b7",
      "metadata": {
        "id": "407e07b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "QUESTION_FIELD = \"question\"\n",
        "\n",
        "CONTEXT_FIELD = \"context\"\n",
        "\n",
        "LANG_FIELD = \"lang\"\n",
        "\n",
        "LANGUAGES = [\"ar\", \"ko\", \"te\", \"en\"]\n",
        "\n",
        "N_ORDERS = [2, 3]\n",
        "\n",
        "MIN_FREQ = 3\n",
        "\n",
        "SMOOTHINGS= [\"laplace\", \"kn\", \"wb\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "75fa5a94",
      "metadata": {
        "id": "75fa5a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946fd48f-d988-4091-ef19-696f71de88f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # ne\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize      # Arabic\n",
        "from konlpy.tag import Okt                                        # Korean\n",
        "from indicnlp.tokenize import indic_tokenize                      # Telugu\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def get_tokenizer(lang: str):\n",
        "    if lang == \"en\":\n",
        "        return nltk.word_tokenize\n",
        "    elif lang == \"ar\":\n",
        "        return simple_word_tokenize\n",
        "    elif lang == \"ko\":\n",
        "        return okt.morphs\n",
        "    elif lang == \"te\":\n",
        "        return lambda text: list(indic_tokenize.trivial_tokenize(text))\n",
        "    else:\n",
        "        # fallback: split on words\n",
        "        return nltk.word_tokenize\n",
        "\n",
        "def tokenize_column(series, lang: str):\n",
        "    tokenizer = get_tokenizer(lang)\n",
        "    out = []\n",
        "    for x in series:\n",
        "        if not isinstance(x, str):\n",
        "            x = \"\" if x is None else str(x)\n",
        "        x = x.lower()\n",
        "        out.append(tokenizer(x))\n",
        "    return out\n",
        "\n",
        "def build_vocab(tokenized: List[List[str]], min_freq: int = 1) -> Dict[str, int]:\n",
        "    cnt = Counter(w for s in tokenized for w in s)\n",
        "    vocab = {w: i for i, (w, c) in enumerate(cnt.items()) if c >= min_freq}\n",
        "    vocab[\"<OOV>\"] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def apply_oov(tokenized: List[List[str]], vocab: Dict[str, int]) -> List[List[str]]:\n",
        "    return [[w if w in vocab else \"<OOV>\" for w in s] for s in tokenized]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "79dd61f9",
      "metadata": {
        "id": "79dd61f9"
      },
      "outputs": [],
      "source": [
        "def train_lm(tokenized: List[List[str]], order: int = 2, smoothing: str = \"laplace\"):\n",
        "    smoothing = (smoothing or \"\").lower()\n",
        "    if smoothing in {\"\", \"mle\"}:\n",
        "        model = MLE(order)\n",
        "    elif smoothing in {\"laplace\", \"addone\", \"add-one\"}:\n",
        "        model = Laplace(order)\n",
        "    elif smoothing in {\"kn\", \"kneserney\", \"kneser-ney\"}:\n",
        "        model = KneserNeyInterpolated(order)\n",
        "    elif smoothing in {\"wb\"}:\n",
        "        model = WittenBellInterpolated(order)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported smoothing: {smoothing}\")\n",
        "\n",
        "    train_data, vocab = padded_everygram_pipeline(order, tokenized)\n",
        "\n",
        "    model.fit(train_data, vocab)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c5da10df",
      "metadata": {
        "id": "c5da10df"
      },
      "outputs": [],
      "source": [
        "def corpus_perplexity(model, tokenized: List[List[str]], order: int) -> dict:\n",
        "    total_logp = 0.0\n",
        "    total_count = 0\n",
        "    for sent in tokenized:\n",
        "        padded = list(pad_both_ends(sent, n=order))  # add <s>, </s>\n",
        "        for ng in ngrams(padded, order):\n",
        "            ctx = ng[:-1]\n",
        "            w   = ng[-1]\n",
        "            p = model.score(w, ctx)\n",
        "            if p <= 0.0:\n",
        "                p = 1e-12  # guard\n",
        "            total_logp += math.log(p)\n",
        "            total_count += 1\n",
        "    ce  = - total_logp / max(total_count, 1)   # cross-entropy\n",
        "    ppl = math.exp(ce)                         # perplexity\n",
        "    return {\"cross_entropy\": ce, \"perplexity\": ppl, \"tokens_counted\": total_count}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5509924d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5509924d",
        "outputId": "2a3fd0de-67f9-4a03-faeb-29349135f3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶ Language: ar | train=2558 | valid=415\n",
            "  n=2  laplace: PPL=34.56  CE=3.5428  tokens=3457\n",
            "  n=2  kn: PPL=13.23  CE=2.5825  tokens=3457\n",
            "  n=2  wb: PPL=12.83  CE=2.5519  tokens=3457\n",
            "  n=3  laplace: PPL=54.72  CE=4.0023  tokens=3872\n",
            "  n=3  kn: PPL=12.03  CE=2.4878  tokens=3872\n",
            "  n=3  wb: PPL=9.78  CE=2.2801  tokens=3872\n",
            "\n",
            "▶ Language: ko | train=2422 | valid=356\n",
            "  n=2  laplace: PPL=30.41  CE=3.4148  tokens=3608\n",
            "  n=2  kn: PPL=11.89  CE=2.4756  tokens=3608\n",
            "  n=2  wb: PPL=11.51  CE=2.4429  tokens=3608\n",
            "  n=3  laplace: PPL=49.59  CE=3.9037  tokens=3964\n",
            "  n=3  kn: PPL=9.71  CE=2.2728  tokens=3964\n",
            "  n=3  wb: PPL=8.16  CE=2.0992  tokens=3964\n",
            "\n",
            "▶ Language: te | train=1355 | valid=384\n",
            "  n=2  laplace: PPL=30.61  CE=3.4214  tokens=3074\n",
            "  n=2  kn: PPL=10.99  CE=2.3966  tokens=3074\n",
            "  n=2  wb: PPL=10.89  CE=2.3879  tokens=3074\n",
            "  n=3  laplace: PPL=43.59  CE=3.7747  tokens=3458\n",
            "  n=3  kn: PPL=8.54  CE=2.1443  tokens=3458\n",
            "  n=3  wb: PPL=7.28  CE=1.9854  tokens=3458\n",
            "\n",
            "▶ Language: en | train=15343 | valid=3011\n",
            "  n=2  laplace: PPL=1508.92  CE=7.3192  tokens=353455\n",
            "  n=2  wb: PPL=209.77  CE=5.3460  tokens=353455\n",
            "  n=3  laplace: PPL=8069.52  CE=8.9958  tokens=356466\n",
            "  n=3  wb: PPL=146.71  CE=4.9885  tokens=356466\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    # pick the text column(s)\n",
        "    if lang == \"en\":\n",
        "        tr_series = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        # exclude KN for English\n",
        "        smoothings_here = [s for s in SMOOTHINGS\n",
        "                           if s.lower() not in {\"kn\"}]\n",
        "    else:\n",
        "        tr_series = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        # use all listed smoothings\n",
        "        smoothings_here = SMOOTHINGS[:]\n",
        "\n",
        "    print(f\"\\n▶ Language: {lang} | train={len(tr_series)} | valid={len(va_series)}\")\n",
        "\n",
        "    # tokenize\n",
        "    tr_tok = tokenize_column(tr_series, lang)\n",
        "    va_tok = tokenize_column(va_series, lang)\n",
        "\n",
        "    # vocab + <UNK>\n",
        "    vocab     = build_vocab(tr_tok, min_freq=MIN_FREQ)\n",
        "    tr_tok_u  = apply_oov(tr_tok, vocab)\n",
        "    va_tok_u  = apply_oov(va_tok, vocab)\n",
        "\n",
        "    # train/eval for each n and smoothing\n",
        "    for n in N_ORDERS:\n",
        "        for s in smoothings_here:\n",
        "            lm = train_lm(tr_tok_u, order=n, smoothing=s)\n",
        "            metrics = corpus_perplexity(lm, va_tok_u, order=n)\n",
        "            results.append({\n",
        "                \"language\": lang,\n",
        "                \"vocab_size\" : len(vocab),\n",
        "                \"order\": n,\n",
        "                \"smoothing\": s,\n",
        "                **metrics\n",
        "            })\n",
        "            print(f\"  n={n}  {s}: PPL={metrics['perplexity']:.2f}  CE={metrics['cross_entropy']:.4f}  tokens={metrics['tokens_counted']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2c3cfccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "2c3cfccd",
        "outputId": "2f78d299-3e19-468b-e1eb-b3e421af2e43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   language  vocab_size  order smoothing  cross_entropy   perplexity  \\\n",
              "0        ar         965      2   laplace       3.542808    34.563823   \n",
              "1        ar         965      2        kn       2.582526    13.230522   \n",
              "2        ar         965      2        wb       2.551880    12.831205   \n",
              "3        ar         965      3   laplace       4.002280    54.722794   \n",
              "4        ar         965      3        kn       2.487780    12.034535   \n",
              "5        ar         965      3        wb       2.280074     9.777403   \n",
              "18       en       29119      2   laplace       7.319152  1508.923553   \n",
              "19       en       29119      2        wb       5.346028   209.773333   \n",
              "20       en       29119      3   laplace       8.995849  8069.521425   \n",
              "21       en       29119      3        wb       4.988482   146.713584   \n",
              "6        ko         755      2   laplace       3.414756    30.409543   \n",
              "7        ko         755      2        kn       2.475640    11.889310   \n",
              "8        ko         755      2        wb       2.442945    11.506884   \n",
              "9        ko         755      3   laplace       3.903742    49.587640   \n",
              "10       ko         755      3        kn       2.272751     9.706070   \n",
              "11       ko         755      3        wb       2.099194     8.159591   \n",
              "12       te         479      2   laplace       3.421393    30.612033   \n",
              "13       te         479      2        kn       2.396618    10.985954   \n",
              "14       te         479      2        wb       2.387861    10.890179   \n",
              "15       te         479      3   laplace       3.774726    43.585584   \n",
              "16       te         479      3        kn       2.144345     8.536447   \n",
              "17       te         479      3        wb       1.985429     7.282172   \n",
              "\n",
              "    tokens_counted  \n",
              "0             3457  \n",
              "1             3457  \n",
              "2             3457  \n",
              "3             3872  \n",
              "4             3872  \n",
              "5             3872  \n",
              "18          353455  \n",
              "19          353455  \n",
              "20          356466  \n",
              "21          356466  \n",
              "6             3608  \n",
              "7             3608  \n",
              "8             3608  \n",
              "9             3964  \n",
              "10            3964  \n",
              "11            3964  \n",
              "12            3074  \n",
              "13            3074  \n",
              "14            3074  \n",
              "15            3458  \n",
              "16            3458  \n",
              "17            3458  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1839352-5c94-4ea7-97b6-cc3597ec0749\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>vocab_size</th>\n",
              "      <th>order</th>\n",
              "      <th>smoothing</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>tokens_counted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.542808</td>\n",
              "      <td>34.563823</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.582526</td>\n",
              "      <td>13.230522</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.551880</td>\n",
              "      <td>12.831205</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>4.002280</td>\n",
              "      <td>54.722794</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.487780</td>\n",
              "      <td>12.034535</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.280074</td>\n",
              "      <td>9.777403</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>7.319152</td>\n",
              "      <td>1508.923553</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>5.346028</td>\n",
              "      <td>209.773333</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>8.995849</td>\n",
              "      <td>8069.521425</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>4.988482</td>\n",
              "      <td>146.713584</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.414756</td>\n",
              "      <td>30.409543</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.475640</td>\n",
              "      <td>11.889310</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.442945</td>\n",
              "      <td>11.506884</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.903742</td>\n",
              "      <td>49.587640</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.272751</td>\n",
              "      <td>9.706070</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.099194</td>\n",
              "      <td>8.159591</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.421393</td>\n",
              "      <td>30.612033</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.396618</td>\n",
              "      <td>10.985954</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.387861</td>\n",
              "      <td>10.890179</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.774726</td>\n",
              "      <td>43.585584</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.144345</td>\n",
              "      <td>8.536447</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>1.985429</td>\n",
              "      <td>7.282172</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1839352-5c94-4ea7-97b6-cc3597ec0749')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dec13ff1-0510-4567-a203-b01b7e197824\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dec13ff1-0510-4567-a203-b01b7e197824')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dec13ff1-0510-4567-a203-b01b7e197824 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "res_df",
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"en\",\n          \"te\",\n          \"ar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocab_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11207,\n        \"min\": 479,\n        \"max\": 29119,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          29119,\n          479,\n          965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoothing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"laplace\",\n          \"kn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cross_entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7914186005531387,\n        \"min\": 1.9854291586476187,\n        \"max\": 8.995849456524624,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.5428075501976486,\n          3.903741618527157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1727.1523733177587,\n        \"min\": 7.282171921998289,\n        \"max\": 8069.521424944306,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          34.5638227638145,\n          49.58764046605111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_counted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138719,\n        \"min\": 3074,\n        \"max\": 356466,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3872,\n          3964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "res_df = pd.DataFrame(results).sort_values([\"language\",\"order\"])\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POTENTIAL NEURAL MODEL ???"
      ],
      "metadata": {
        "id": "PqNPCPGv9sms"
      },
      "id": "PqNPCPGv9sms"
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed (Colab/new env), uncomment:\n",
        "# !pip install -q bpemb torch\n",
        "\n",
        "import math, re, random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from bpemb import BPEmb\n"
      ],
      "metadata": {
        "id": "CqYMZhk7KRw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "a722219a-153c-417d-8706-97cf3f464e50"
      },
      "id": "CqYMZhk7KRw7",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bpemb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2645729378.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbpemb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBPEmb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bpemb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED      = 42\n",
        "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# training knobs (start small, bump after it works)\n",
        "EPOCHS    = 10\n",
        "BATCH     = 128\n",
        "SEQ_LEN   = 120\n",
        "EMB_DIM   = 100      # must match bpemb dim\n",
        "HIDDEN    = 256\n",
        "LAYERS    = 2\n",
        "DROPOUT   = 0.2\n",
        "LR        = 2e-3\n",
        "CLIP      = 1.0\n",
        "\n",
        "# bpemb options\n",
        "# Option A (per-language): ar/ko/te/en separately — best quality\n",
        "BPE_PER_LANGUAGE = True\n",
        "BP_VS   = 5000    # vocab size\n",
        "BP_DIM  = EMB_DIM   # should equal EMB_DIM\n",
        "\n",
        "# Option B (single multilingual model): use 'multi'\n",
        "# BPE_PER_LANGUAGE = False\n",
        "# BP_LANG = \"multi\"     # uncomment to try multilingual model\n",
        "\n",
        "# light text normalization\n",
        "LOWERCASE    = True\n",
        "FOLD_NUMBERS = True\n",
        "\n",
        "# throttle English contexts (they’re huge)\n",
        "EN_MAX_ROWS_TRAIN    = 30000\n",
        "EN_MAX_ROWS_VALID    = 5000\n",
        "EN_MAX_TOK_PER_DOC   = 400      # subword pieces per doc (for speed)\n",
        "FREEZE_EMBEDDINGS    = True     # False = fine-tune embeddings\n"
      ],
      "metadata": {
        "id": "n980Tf6kS6_0"
      },
      "id": "n980Tf6kS6_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ],
      "metadata": {
        "id": "QZAwr540TOEO"
      },
      "id": "QZAwr540TOEO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ],
      "metadata": {
        "id": "c-SIaeTdTPuS"
      },
      "id": "c-SIaeTdTPuS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_bp_cache = {}\n",
        "\n",
        "def load_bpemb_for_lang(lang: str):\n",
        "    if BPE_PER_LANGUAGE:\n",
        "        key = f\"{lang}:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=lang, vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "    else:\n",
        "        key = f\"multi:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=\"multi\", vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "\n",
        "def build_embedding_matrix(bp: BPEmb):\n",
        "    # bp.emb.vectors shape: (vs, dim)\n",
        "    pad_vec = np.zeros((1, BP_DIM), dtype=np.float32)\n",
        "    eos_vec = np.zeros((1, BP_DIM), dtype=np.float32)  # simple; could be mean vector\n",
        "    mat = np.concatenate([bp.emb.vectors, pad_vec, eos_vec], axis=0).astype(np.float32)\n",
        "    pad_id = bp.emb.vectors.shape[0]        # PAD index\n",
        "    eos_id = bp.emb.vectors.shape[0] + 1    # EOS index\n",
        "    return torch.tensor(mat), pad_id, eos_id\n"
      ],
      "metadata": {
        "id": "XTdgQlx4TUVo"
      },
      "id": "XTdgQlx4TUVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d)  # list of subword ids (0..vs-1)\n",
        "        if max_len_per_doc:    # throttle long docs (esp. English)\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ],
      "metadata": {
        "id": "-ISId1NZTXES"
      },
      "id": "-ISId1NZTXES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d)  # list of subword ids (0..vs-1)\n",
        "        if max_len_per_doc:    # throttle long docs (esp. English)\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ],
      "metadata": {
        "id": "BwPuUPY4TYnR"
      },
      "id": "BwPuUPY4TYnR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WPLSTMLM(nn.Module):\n",
        "    def __init__(self, emb_matrix: torch.Tensor, pad_id: int, hidden=256, layers=2, dropout=0.2, freeze=True):\n",
        "        super().__init__()\n",
        "        V, D = emb_matrix.shape\n",
        "        self.embed = nn.Embedding.from_pretrained(emb_matrix, freeze=freeze, padding_idx=pad_id)\n",
        "        self.lstm  = nn.LSTM(D, hidden, num_layers=layers, dropout=dropout, batch_first=True)\n",
        "        self.drop  = nn.Dropout(dropout)\n",
        "        self.head  = nn.Linear(hidden, V)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embed(x)\n",
        "        x, h = self.lstm(x, h)\n",
        "        x = self.drop(x)\n",
        "        logits = self.head(x)\n",
        "        return logits, h\n"
      ],
      "metadata": {
        "id": "bw0gFkvaTbJp"
      },
      "id": "bw0gFkvaTbJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_tok = 0.0, 0\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")  # sum, we divide later\n",
        "    for x, y in loader:\n",
        "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "        logits, _ = model(x)\n",
        "        loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "        total_tok  += y.numel()\n",
        "    ce  = total_loss / max(total_tok, 1)   # natural log\n",
        "    ppl = math.exp(ce)\n",
        "    return ce, ppl, total_tok\n",
        "\n",
        "def train_bpemb_lm(lang, train_series, valid_series, max_tok_per_doc=None):\n",
        "    set_seed()\n",
        "    bp   = load_bpemb_for_lang(lang if BPE_PER_LANGUAGE else \"multi\")\n",
        "    embM, pad_id, eos_id = build_embedding_matrix(bp)\n",
        "\n",
        "    ids_tr = encode_docs_to_stream(bp, list(train_series), eos_id, max_tok_per_doc)\n",
        "    ids_va = encode_docs_to_stream(bp, list(valid_series), eos_id, max_tok_per_doc)\n",
        "\n",
        "    tr_dl, va_dl = make_loaders(ids_tr, ids_va, SEQ_LEN, BATCH)\n",
        "\n",
        "    model = WPLSTMLM(embM, pad_id, hidden=HIDDEN, layers=LAYERS, dropout=DROPOUT, freeze=FREEZE_EMBEDDINGS).to(DEVICE)\n",
        "    opt   = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "\n",
        "    print(f\"[{lang}] subword_vocab={embM.size(0)} train_batches={len(tr_dl)} valid_batches={len(va_dl)} device={DEVICE}\")\n",
        "\n",
        "    best = float(\"inf\")\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total, steps = 0.0, 0\n",
        "        crit = nn.CrossEntropyLoss()\n",
        "        for x, y in tr_dl:\n",
        "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits, _ = model(x)\n",
        "            loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "            opt.step()\n",
        "            total += loss.item(); steps += 1\n",
        "        sched.step()\n",
        "        ce, ppl, tok = evaluate(model, va_dl)\n",
        "        best = min(best, ppl)\n",
        "        print(f\"  epoch {ep:02d}  train_ce={total/max(steps,1):.4f}  val_ce={ce:.4f}  val_ppl={ppl:.2f}  tokens={tok}\")\n",
        "    return best\n"
      ],
      "metadata": {
        "id": "AtVVDz0GTe3a"
      },
      "id": "AtVVDz0GTe3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bpemb_results = []\n",
        "for lang in LANGUAGES:\n",
        "    tr, va, max_len = get_series(lang)\n",
        "    print(f\"\\n▶ BPEmb LSTM on {lang}: train_rows={len(tr)} valid_rows={len(va)}\")\n",
        "    best_ppl = train_bpemb_lm(lang if lang!=\"en\" else \"en\", tr, va, max_tok_per_doc=max_len)\n",
        "    bpemb_results.append({\"language\": lang, \"model\": \"bpemb_lstm\", \"best_ppl\": best_ppl})\n",
        "\n",
        "bpemb_results\n"
      ],
      "metadata": {
        "id": "MoOHavS7TiN0"
      },
      "id": "MoOHavS7TiN0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}