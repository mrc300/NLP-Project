{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2a21598",
      "metadata": {
        "id": "b2a21598"
      },
      "source": [
        "# WEEK 37\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50500cb8",
      "metadata": {
        "id": "50500cb8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Iterable\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import MLE, Laplace, KneserNeyInterpolated,  WittenBellInterpolated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4cdd5a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cdd5a3",
        "outputId": "9072dba1-1c9f-458b-a9ec-93774732f0f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question  \\\n",
            "0  উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...   \n",
            "1           দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?   \n",
            "2  মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...   \n",
            "3  আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...   \n",
            "4          বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  WikiLeaks () is an international non-profit or...   bn        True   \n",
            "1  The war in Europe concluded with an invasion o...   bn        True   \n",
            "2  Same-sex marriage in the United States expande...   bn       False   \n",
            "3  The exact number of Arab casualties is unknown...   bn        True   \n",
            "4  As Thomas Hall (2000) notes, \"The Sung Empire ...   bn        True   \n",
            "\n",
            "   answer_start        answer answer_inlang  \n",
            "0           182          2006          None  \n",
            "1            48       Germany          None  \n",
            "2            -1            no          None  \n",
            "3            39       unknown          None  \n",
            "4          1219  17th century          None  \n",
            "                                      question  \\\n",
            "0     ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది ?   \n",
            "1  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "2  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "3      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "4      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  Portland is the largest city in the U.S. state...   te        True   \n",
            "1  The word cholera is from \"kholera\" from χολή \"...   te        True   \n",
            "2  Since it became widespread in the 19th century...   te        True   \n",
            "3  World War I occurred from 1914 to 1918. In ter...   te        True   \n",
            "4  World War I (often abbreviated as WWI or WW1),...   te        True   \n",
            "\n",
            "   answer_start               answer answer_inlang  \n",
            "0             0             Portland          None  \n",
            "1            99  Indian subcontinent          None  \n",
            "2           451              England          None  \n",
            "3            26                 1914          None  \n",
            "4           155         28 July 1914          None  \n"
          ]
        }
      ],
      "source": [
        "## K = 3\n",
        "\n",
        "#DOWNLOAD DATASET\n",
        "\n",
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "print(df_train.head())\n",
        "print(df_val.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407e07b7",
      "metadata": {
        "id": "407e07b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "QUESTION_FIELD = \"question\"\n",
        "\n",
        "CONTEXT_FIELD = \"context\"\n",
        "\n",
        "LANG_FIELD = \"lang\"\n",
        "\n",
        "LANGUAGES = [\"ar\", \"ko\", \"te\", \"en\"]\n",
        "\n",
        "N_ORDERS = [2, 3]\n",
        "\n",
        "MIN_FREQ = 3\n",
        "\n",
        "SMOOTHINGS= [\"laplace\", \"kn\", \"wb\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fa5a94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fa5a94",
        "outputId": "946fd48f-d988-4091-ef19-696f71de88f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # ne\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize      # Arabic\n",
        "from konlpy.tag import Okt                                        # Korean\n",
        "from indicnlp.tokenize import indic_tokenize                      # Telugu\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def get_tokenizer(lang: str):\n",
        "    if lang == \"en\":\n",
        "        return nltk.word_tokenize\n",
        "    elif lang == \"ar\":\n",
        "        return simple_word_tokenize\n",
        "    elif lang == \"ko\":\n",
        "        return okt.morphs\n",
        "    elif lang == \"te\":\n",
        "        return lambda text: list(indic_tokenize.trivial_tokenize(text))\n",
        "    else:\n",
        "        # fallback: split on words\n",
        "        return nltk.word_tokenize\n",
        "\n",
        "def tokenize_column(series, lang: str):\n",
        "    tokenizer = get_tokenizer(lang)\n",
        "    out = []\n",
        "    for x in series:\n",
        "        if not isinstance(x, str):\n",
        "            x = \"\" if x is None else str(x)\n",
        "        x = x.lower()\n",
        "        out.append(tokenizer(x))\n",
        "    return out\n",
        "\n",
        "def build_vocab(tokenized: List[List[str]], min_freq: int = 1) -> Dict[str, int]:\n",
        "    cnt = Counter(w for s in tokenized for w in s)\n",
        "    vocab = {w: i for i, (w, c) in enumerate(cnt.items()) if c >= min_freq}\n",
        "    vocab[\"<OOV>\"] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def apply_oov(tokenized: List[List[str]], vocab: Dict[str, int]) -> List[List[str]]:\n",
        "    return [[w if w in vocab else \"<OOV>\" for w in s] for s in tokenized]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79dd61f9",
      "metadata": {
        "id": "79dd61f9"
      },
      "outputs": [],
      "source": [
        "def train_lm(tokenized: List[List[str]], order: int = 2, smoothing: str = \"laplace\"):\n",
        "    smoothing = (smoothing or \"\").lower()\n",
        "    if smoothing in {\"\", \"mle\"}:\n",
        "        model = MLE(order)\n",
        "    elif smoothing in {\"laplace\", \"addone\", \"add-one\"}:\n",
        "        model = Laplace(order)\n",
        "    elif smoothing in {\"kn\", \"kneserney\", \"kneser-ney\"}:\n",
        "        model = KneserNeyInterpolated(order)\n",
        "    elif smoothing in {\"wb\"}:\n",
        "        model = WittenBellInterpolated(order)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported smoothing: {smoothing}\")\n",
        "\n",
        "    train_data, vocab = padded_everygram_pipeline(order, tokenized)\n",
        "\n",
        "    model.fit(train_data, vocab)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5da10df",
      "metadata": {
        "id": "c5da10df"
      },
      "outputs": [],
      "source": [
        "def corpus_perplexity(model, tokenized: List[List[str]], order: int) -> dict:\n",
        "    total_logp = 0.0\n",
        "    total_count = 0\n",
        "    for sent in tokenized:\n",
        "        padded = list(pad_both_ends(sent, n=order))  # add <s>, </s>\n",
        "        for ng in ngrams(padded, order):\n",
        "            ctx = ng[:-1]\n",
        "            w   = ng[-1]\n",
        "            p = model.score(w, ctx)\n",
        "            if p <= 0.0:\n",
        "                p = 1e-12  # guard\n",
        "            total_logp += math.log(p)\n",
        "            total_count += 1\n",
        "    ce  = - total_logp / max(total_count, 1)   # cross-entropy\n",
        "    ppl = math.exp(ce)                         # perplexity\n",
        "    return {\"cross_entropy\": ce, \"perplexity\": ppl, \"tokens_counted\": total_count}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5509924d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5509924d",
        "outputId": "2a3fd0de-67f9-4a03-faeb-29349135f3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "▶ Language: ar | train=2558 | valid=415\n",
            "  n=2  laplace: PPL=34.56  CE=3.5428  tokens=3457\n",
            "  n=2  kn: PPL=13.23  CE=2.5825  tokens=3457\n",
            "  n=2  wb: PPL=12.83  CE=2.5519  tokens=3457\n",
            "  n=3  laplace: PPL=54.72  CE=4.0023  tokens=3872\n",
            "  n=3  kn: PPL=12.03  CE=2.4878  tokens=3872\n",
            "  n=3  wb: PPL=9.78  CE=2.2801  tokens=3872\n",
            "\n",
            "▶ Language: ko | train=2422 | valid=356\n",
            "  n=2  laplace: PPL=30.41  CE=3.4148  tokens=3608\n",
            "  n=2  kn: PPL=11.89  CE=2.4756  tokens=3608\n",
            "  n=2  wb: PPL=11.51  CE=2.4429  tokens=3608\n",
            "  n=3  laplace: PPL=49.59  CE=3.9037  tokens=3964\n",
            "  n=3  kn: PPL=9.71  CE=2.2728  tokens=3964\n",
            "  n=3  wb: PPL=8.16  CE=2.0992  tokens=3964\n",
            "\n",
            "▶ Language: te | train=1355 | valid=384\n",
            "  n=2  laplace: PPL=30.61  CE=3.4214  tokens=3074\n",
            "  n=2  kn: PPL=10.99  CE=2.3966  tokens=3074\n",
            "  n=2  wb: PPL=10.89  CE=2.3879  tokens=3074\n",
            "  n=3  laplace: PPL=43.59  CE=3.7747  tokens=3458\n",
            "  n=3  kn: PPL=8.54  CE=2.1443  tokens=3458\n",
            "  n=3  wb: PPL=7.28  CE=1.9854  tokens=3458\n",
            "\n",
            "▶ Language: en | train=15343 | valid=3011\n",
            "  n=2  laplace: PPL=1508.92  CE=7.3192  tokens=353455\n",
            "  n=2  wb: PPL=209.77  CE=5.3460  tokens=353455\n",
            "  n=3  laplace: PPL=8069.52  CE=8.9958  tokens=356466\n",
            "  n=3  wb: PPL=146.71  CE=4.9885  tokens=356466\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    # pick the text column(s)\n",
        "    if lang == \"en\":\n",
        "        tr_series = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        # exclude KN for English\n",
        "        smoothings_here = [s for s in SMOOTHINGS\n",
        "                           if s.lower() not in {\"kn\"}]\n",
        "    else:\n",
        "        tr_series = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        # use all listed smoothings\n",
        "        smoothings_here = SMOOTHINGS[:]\n",
        "\n",
        "    print(f\"\\n▶ Language: {lang} | train={len(tr_series)} | valid={len(va_series)}\")\n",
        "\n",
        "    # tokenize\n",
        "    tr_tok = tokenize_column(tr_series, lang)\n",
        "    va_tok = tokenize_column(va_series, lang)\n",
        "\n",
        "    # vocab + <UNK>\n",
        "    vocab     = build_vocab(tr_tok, min_freq=MIN_FREQ)\n",
        "    tr_tok_u  = apply_oov(tr_tok, vocab)\n",
        "    va_tok_u  = apply_oov(va_tok, vocab)\n",
        "\n",
        "    # train/eval for each n and smoothing\n",
        "    for n in N_ORDERS:\n",
        "        for s in smoothings_here:\n",
        "            lm = train_lm(tr_tok_u, order=n, smoothing=s)\n",
        "            metrics = corpus_perplexity(lm, va_tok_u, order=n)\n",
        "            results.append({\n",
        "                \"language\": lang,\n",
        "                \"vocab_size\" : len(vocab),\n",
        "                \"order\": n,\n",
        "                \"smoothing\": s,\n",
        "                **metrics\n",
        "            })\n",
        "            print(f\"  n={n}  {s}: PPL={metrics['perplexity']:.2f}  CE={metrics['cross_entropy']:.4f}  tokens={metrics['tokens_counted']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3cfccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "2c3cfccd",
        "outputId": "2f78d299-3e19-468b-e1eb-b3e421af2e43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"en\",\n          \"te\",\n          \"ar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocab_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11207,\n        \"min\": 479,\n        \"max\": 29119,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          29119,\n          479,\n          965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoothing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"laplace\",\n          \"kn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cross_entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7914186005531387,\n        \"min\": 1.9854291586476187,\n        \"max\": 8.995849456524624,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.5428075501976486,\n          3.903741618527157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1727.1523733177587,\n        \"min\": 7.282171921998289,\n        \"max\": 8069.521424944306,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          34.5638227638145,\n          49.58764046605111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_counted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138719,\n        \"min\": 3074,\n        \"max\": 356466,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3872,\n          3964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "res_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b1839352-5c94-4ea7-97b6-cc3597ec0749\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>vocab_size</th>\n",
              "      <th>order</th>\n",
              "      <th>smoothing</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>tokens_counted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.542808</td>\n",
              "      <td>34.563823</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.582526</td>\n",
              "      <td>13.230522</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.551880</td>\n",
              "      <td>12.831205</td>\n",
              "      <td>3457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>4.002280</td>\n",
              "      <td>54.722794</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.487780</td>\n",
              "      <td>12.034535</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ar</td>\n",
              "      <td>965</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.280074</td>\n",
              "      <td>9.777403</td>\n",
              "      <td>3872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>7.319152</td>\n",
              "      <td>1508.923553</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>5.346028</td>\n",
              "      <td>209.773333</td>\n",
              "      <td>353455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>8.995849</td>\n",
              "      <td>8069.521425</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>en</td>\n",
              "      <td>29119</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>4.988482</td>\n",
              "      <td>146.713584</td>\n",
              "      <td>356466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.414756</td>\n",
              "      <td>30.409543</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.475640</td>\n",
              "      <td>11.889310</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.442945</td>\n",
              "      <td>11.506884</td>\n",
              "      <td>3608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.903742</td>\n",
              "      <td>49.587640</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.272751</td>\n",
              "      <td>9.706070</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ko</td>\n",
              "      <td>755</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.099194</td>\n",
              "      <td>8.159591</td>\n",
              "      <td>3964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.421393</td>\n",
              "      <td>30.612033</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.396618</td>\n",
              "      <td>10.985954</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.387861</td>\n",
              "      <td>10.890179</td>\n",
              "      <td>3074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.774726</td>\n",
              "      <td>43.585584</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.144345</td>\n",
              "      <td>8.536447</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>te</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>1.985429</td>\n",
              "      <td>7.282172</td>\n",
              "      <td>3458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1839352-5c94-4ea7-97b6-cc3597ec0749')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1839352-5c94-4ea7-97b6-cc3597ec0749');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dec13ff1-0510-4567-a203-b01b7e197824\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dec13ff1-0510-4567-a203-b01b7e197824')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dec13ff1-0510-4567-a203-b01b7e197824 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8a7f5fd7-8f65-402e-bed7-23fb2cc4656f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   language  vocab_size  order smoothing  cross_entropy   perplexity  \\\n",
              "0        ar         965      2   laplace       3.542808    34.563823   \n",
              "1        ar         965      2        kn       2.582526    13.230522   \n",
              "2        ar         965      2        wb       2.551880    12.831205   \n",
              "3        ar         965      3   laplace       4.002280    54.722794   \n",
              "4        ar         965      3        kn       2.487780    12.034535   \n",
              "5        ar         965      3        wb       2.280074     9.777403   \n",
              "18       en       29119      2   laplace       7.319152  1508.923553   \n",
              "19       en       29119      2        wb       5.346028   209.773333   \n",
              "20       en       29119      3   laplace       8.995849  8069.521425   \n",
              "21       en       29119      3        wb       4.988482   146.713584   \n",
              "6        ko         755      2   laplace       3.414756    30.409543   \n",
              "7        ko         755      2        kn       2.475640    11.889310   \n",
              "8        ko         755      2        wb       2.442945    11.506884   \n",
              "9        ko         755      3   laplace       3.903742    49.587640   \n",
              "10       ko         755      3        kn       2.272751     9.706070   \n",
              "11       ko         755      3        wb       2.099194     8.159591   \n",
              "12       te         479      2   laplace       3.421393    30.612033   \n",
              "13       te         479      2        kn       2.396618    10.985954   \n",
              "14       te         479      2        wb       2.387861    10.890179   \n",
              "15       te         479      3   laplace       3.774726    43.585584   \n",
              "16       te         479      3        kn       2.144345     8.536447   \n",
              "17       te         479      3        wb       1.985429     7.282172   \n",
              "\n",
              "    tokens_counted  \n",
              "0             3457  \n",
              "1             3457  \n",
              "2             3457  \n",
              "3             3872  \n",
              "4             3872  \n",
              "5             3872  \n",
              "18          353455  \n",
              "19          353455  \n",
              "20          356466  \n",
              "21          356466  \n",
              "6             3608  \n",
              "7             3608  \n",
              "8             3608  \n",
              "9             3964  \n",
              "10            3964  \n",
              "11            3964  \n",
              "12            3074  \n",
              "13            3074  \n",
              "14            3074  \n",
              "15            3458  \n",
              "16            3458  \n",
              "17            3458  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_df = pd.DataFrame(results).sort_values([\"language\",\"order\"])\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PqNPCPGv9sms",
      "metadata": {
        "id": "PqNPCPGv9sms"
      },
      "source": [
        "### POTENTIAL NEURAL MODEL ???"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q pandas fsspec huggingface_hub transformers torch --upgrade\n",
        "import math, numpy as np, pandas as pd, torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# --- Daten laden ---\n",
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "\n",
        "langs = [\"ar\",\"ko\",\"te\"]\n",
        "val_questions = {L: df_val.loc[df_val[\"lang\"]==L, \"question\"].astype(str).tolist() for L in langs}\n",
        "val_contexts_en = df_val[\"context\"].astype(str).tolist()\n",
        "\n",
        "# --- Modell laden (Warning bzgl. Pooler ist erwartbar/ok) ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "name = \"xlm-roberta-base\"\n",
        "tok  = AutoTokenizer.from_pretrained(name)\n",
        "mdl  = AutoModelForMaskedLM.from_pretrained(name).to(device).eval()\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "@torch.inference_mode()\n",
        "def pll_pseudo_perplexity_batched(texts, max_len=128, max_texts=100, pos_chunk=32):\n",
        "    texts = [t for t in texts if isinstance(t, str) and t.strip()]\n",
        "    if max_texts is not None:\n",
        "        texts = texts[:max_texts]\n",
        "\n",
        "    ppl_list = []\n",
        "\n",
        "    for txt in texts:\n",
        "        ids = tok(txt, return_tensors=\"pt\", truncation=True, max_length=max_len).input_ids.to(device)\n",
        "        if ids.size(1) <= 2:\n",
        "            continue\n",
        "        seq = ids[0]\n",
        "        positions = list(range(1, seq.size(0)-1))  # ignoriere <s> und </s>\n",
        "        logprob_sum = 0.0\n",
        "        count = 0\n",
        "\n",
        "        # in Chunks verarbeiten\n",
        "        for i in range(0, len(positions), pos_chunk):\n",
        "            chunk_pos = positions[i:i+pos_chunk]\n",
        "            # Batch mit kopierten Sequenzen, jede mit *einer* anderen Position maskiert\n",
        "            batch = seq.unsqueeze(0).repeat(len(chunk_pos), 1)\n",
        "            for r, p in enumerate(chunk_pos):\n",
        "                batch[r, p] = tok.mask_token_id\n",
        "\n",
        "            out = mdl(input_ids=batch)\n",
        "            logits = out.logits  # [B, T, V]\n",
        "            # Hole Logprob am jeweils maskierten Index\n",
        "            for r, p in enumerate(chunk_pos):\n",
        "                tgt_id = int(seq[p].item())\n",
        "                logprob = torch.log_softmax(logits[r, p], dim=-1)[tgt_id].item()\n",
        "                logprob_sum += logprob\n",
        "                count += 1\n",
        "\n",
        "            # Speicher freigeben (wichtig in Colab)\n",
        "            del batch, out, logits\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        if count > 0:\n",
        "            ppl_list.append(math.exp(-logprob_sum / count))\n",
        "\n",
        "    return float(np.mean(ppl_list)) if ppl_list else float(\"nan\")\n",
        "\n",
        "# --- Evaluierung (schnell & stabil) ---\n",
        "results = []\n",
        "for L in langs:\n",
        "    ppl = pll_pseudo_perplexity_batched(val_questions[L], max_len=128, max_texts=100, pos_chunk=32)\n",
        "    results.append(dict(model=\"XLM-R (PLL)\", domain=f\"questions-{L}\", perplexity=round(ppl, 2)))\n",
        "\n",
        "ppl_ctx = pll_pseudo_perplexity_batched(val_contexts_en, max_len=128, max_texts=50, pos_chunk=16)  # Kontexte sind lang → noch konservativer\n",
        "results.append(dict(model=\"XLM-R (PLL)\", domain=\"contexts-en\", perplexity=round(ppl_ctx, 2)))\n",
        "\n",
        "print(pd.DataFrame(results))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fopWNOo_mbY",
        "outputId": "fe8c2f63-a5bb-4c3a-d73f-973f6296d587"
      },
      "id": "7fopWNOo_mbY",
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         model        domain  perplexity\n",
            "0  XLM-R (PLL)  questions-ar      195.47\n",
            "1  XLM-R (PLL)  questions-ko       10.56\n",
            "2  XLM-R (PLL)  questions-te        8.37\n",
            "3  XLM-R (PLL)   contexts-en        3.47\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}