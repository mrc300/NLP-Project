{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2a21598",
      "metadata": {
        "id": "b2a21598"
      },
      "source": [
        "# WEEK 37\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50500cb8",
      "metadata": {
        "id": "50500cb8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Iterable\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import MLE, Laplace, KneserNeyInterpolated,  WittenBellInterpolated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uSbXI9JSUaar",
      "metadata": {
        "id": "uSbXI9JSUaar"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4cdd5a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4cdd5a3",
        "outputId": "13e8444b-7f09-4268-863a-43f1f9e65c83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question  \\\n",
            "0  উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...   \n",
            "1           দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?   \n",
            "2  মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...   \n",
            "3  আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...   \n",
            "4          বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  WikiLeaks () is an international non-profit or...   bn        True   \n",
            "1  The war in Europe concluded with an invasion o...   bn        True   \n",
            "2  Same-sex marriage in the United States expande...   bn       False   \n",
            "3  The exact number of Arab casualties is unknown...   bn        True   \n",
            "4  As Thomas Hall (2000) notes, \"The Sung Empire ...   bn        True   \n",
            "\n",
            "   answer_start        answer answer_inlang  \n",
            "0           182          2006          None  \n",
            "1            48       Germany          None  \n",
            "2            -1            no          None  \n",
            "3            39       unknown          None  \n",
            "4          1219  17th century          None  \n",
            "                                      question  \\\n",
            "0     ఒరెగాన్ రాష్ట్రంలోని అతిపెద్ద నగరం ఏది ?   \n",
            "1  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "2  కలరా వ్యాధిని మొదటగా ఏ దేశంలో కనుగొన్నారు ?   \n",
            "3      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "4      మొదటి ప్రపంచ యుద్ధం ఎప్పుడు మొదలయింది ?   \n",
            "\n",
            "                                             context lang  answerable  \\\n",
            "0  Portland is the largest city in the U.S. state...   te        True   \n",
            "1  The word cholera is from \"kholera\" from χολή \"...   te        True   \n",
            "2  Since it became widespread in the 19th century...   te        True   \n",
            "3  World War I occurred from 1914 to 1918. In ter...   te        True   \n",
            "4  World War I (often abbreviated as WWI or WW1),...   te        True   \n",
            "\n",
            "   answer_start               answer answer_inlang  \n",
            "0             0             Portland          None  \n",
            "1            99  Indian subcontinent          None  \n",
            "2           451              England          None  \n",
            "3            26                 1914          None  \n",
            "4           155         28 July 1914          None  \n"
          ]
        }
      ],
      "source": [
        "## K = 3\n",
        "\n",
        "#DOWNLOAD DATASET\n",
        "\n",
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "print(df_train.head())\n",
        "print(df_val.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407e07b7",
      "metadata": {
        "id": "407e07b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Which text to model (use 'question_text' for the 3 languages; switch to a context column for English)\n",
        "QUESTION_FIELD = \"question\"\n",
        "\n",
        "CONTEXT_FIELD = \"context\"\n",
        "\n",
        "# Which column has language codes for that text\n",
        "LANG_FIELD = \"lang\"  # for questions; change if you model contexts with a different column\n",
        "\n",
        "# Which languages to run (Arabic, Korean, Telugu)\n",
        "LANGUAGES = [\"ar\", \"ko\", \"te\", \"en\"]\n",
        "\n",
        "# n-gram orders to train\n",
        "N_ORDERS = [2, 3]  # bigram, trigram\n",
        "\n",
        "# Keep tokens with frequency >= MIN_FREQ, map others to <UNK>\n",
        "MIN_FREQ = 3\n",
        "\n",
        "SMOOTHINGS= [\"laplace\", \"kn\", \"wb\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fa5a94",
      "metadata": {
        "id": "75fa5a94"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def tokenize_column(series):\n",
        "    out = []\n",
        "    for x in series:\n",
        "        if not isinstance(x, str):\n",
        "            x = \"\" if x is None else str(x)\n",
        "        x = x.lower()\n",
        "        out.append(wordpunct_tokenize(x))\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_vocab(tokenized: List[List[str]], min_freq: int = 1) -> Dict[str, int]:\n",
        "    cnt = Counter(w for s in tokenized for w in s)\n",
        "    vocab = {w: i for i,(w,c) in enumerate(cnt.items()) if c >= min_freq}\n",
        "    vocab[\"<OOV>\"] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def apply_unk(tokenized: List[List[str]], vocab: Dict[str,int]) -> List[List[str]]:\n",
        "    return [[w if w in vocab else \"<OOV>\" for w in s] for s in tokenized]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79dd61f9",
      "metadata": {
        "id": "79dd61f9"
      },
      "outputs": [],
      "source": [
        "def train_lm(tokenized: List[List[str]], order: int = 2, smoothing: str = \"laplace\"):\n",
        "    smoothing = (smoothing or \"\").lower()\n",
        "    if smoothing in {\"\", \"mle\"}:\n",
        "        model = MLE(order)\n",
        "    elif smoothing in {\"laplace\", \"addone\", \"add-one\"}:\n",
        "        model = Laplace(order)\n",
        "    elif smoothing in {\"kn\", \"kneserney\", \"kneser-ney\"}:\n",
        "        model = KneserNeyInterpolated(order)\n",
        "    elif smoothing in {\"wb\"}:\n",
        "        model = WittenBellInterpolated(order)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported smoothing: {smoothing}\")\n",
        "\n",
        "    train_data, vocab = padded_everygram_pipeline(order, tokenized)\n",
        "    model.fit(train_data, vocab)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5da10df",
      "metadata": {
        "id": "c5da10df"
      },
      "outputs": [],
      "source": [
        "def corpus_perplexity(model, tokenized: List[List[str]], order: int) -> dict:\n",
        "    total_logp = 0.0\n",
        "    total_count = 0\n",
        "    for sent in tokenized:\n",
        "        padded = list(pad_both_ends(sent, n=order))  # add <s>, </s>\n",
        "        for ng in ngrams(padded, order):\n",
        "            ctx = ng[:-1]\n",
        "            w   = ng[-1]\n",
        "            p = model.score(w, ctx)\n",
        "            if p <= 0.0:\n",
        "                p = 1e-12  # guard\n",
        "            total_logp += math.log(p)\n",
        "            total_count += 1\n",
        "    ce  = - total_logp / max(total_count, 1)   # cross-entropy\n",
        "    ppl = math.exp(ce)                         # perplexity\n",
        "    return {\"cross_entropy\": ce, \"perplexity\": ppl, \"tokens_counted\": total_count}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5509924d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5509924d",
        "outputId": "4ee01845-24b0-4ccf-d8f8-c26dc06c4ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "▶ Language: ar | train=2558 | valid=415\n",
            "  n=2  laplace: PPL=40.55  CE=3.7025  tokens=3588\n",
            "  n=2  kn: PPL=15.76  CE=2.7572  tokens=3588\n",
            "  n=2  wb: PPL=15.03  CE=2.7103  tokens=3588\n",
            "  n=3  laplace: PPL=63.82  CE=4.1561  tokens=4003\n",
            "  n=3  kn: PPL=14.39  CE=2.6663  tokens=4003\n",
            "  n=3  wb: PPL=11.40  CE=2.4335  tokens=4003\n",
            "\n",
            "▶ Language: ko | train=2422 | valid=356\n",
            "  n=2  laplace: PPL=18.25  CE=2.9039  tokens=2462\n",
            "  n=2  kn: PPL=7.60  CE=2.0275  tokens=2462\n",
            "  n=2  wb: PPL=7.57  CE=2.0240  tokens=2462\n",
            "  n=3  laplace: PPL=25.04  CE=3.2206  tokens=2818\n",
            "  n=3  kn: PPL=6.22  CE=1.8280  tokens=2818\n",
            "  n=3  wb: PPL=5.57  CE=1.7181  tokens=2818\n",
            "\n",
            "▶ Language: te | train=1355 | valid=384\n",
            "  n=2  laplace: PPL=21.19  CE=3.0533  tokens=12658\n",
            "  n=2  kn: PPL=14.07  CE=2.6438  tokens=12658\n",
            "  n=2  wb: PPL=14.11  CE=2.6467  tokens=12658\n",
            "  n=3  laplace: PPL=28.37  CE=3.3454  tokens=13042\n",
            "  n=3  kn: PPL=7.11  CE=1.9619  tokens=13042\n",
            "  n=3  wb: PPL=6.70  CE=1.9023  tokens=13042\n",
            "\n",
            "▶ Language: en | train=15343 | valid=3011\n",
            "  n=2  laplace: PPL=1643.70  CE=7.4047  tokens=363290\n",
            "  n=2  wb: PPL=226.39  CE=5.4222  tokens=363290\n",
            "  n=3  laplace: PPL=8635.29  CE=9.0636  tokens=366301\n",
            "  n=3  wb: PPL=153.18  CE=5.0316  tokens=366301\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "    # pick the text column(s)\n",
        "    if lang == \"en\":\n",
        "        tr_series = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        # exclude KN for English\n",
        "        smoothings_here = [s for s in SMOOTHINGS\n",
        "                           if s.lower() not in {\"kn\"}]\n",
        "    else:\n",
        "        tr_series = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        va_series = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str)\n",
        "        # use all listed smoothings\n",
        "        smoothings_here = SMOOTHINGS[:]\n",
        "\n",
        "    print(f\"\\n▶ Language: {lang} | train={len(tr_series)} | valid={len(va_series)}\")\n",
        "\n",
        "    # tokenize\n",
        "    tr_tok = tokenize_column(tr_series)\n",
        "    va_tok = tokenize_column(va_series)\n",
        "\n",
        "    # vocab + <UNK>\n",
        "    vocab     = build_vocab(tr_tok, min_freq=MIN_FREQ)\n",
        "    tr_tok_u  = apply_unk(tr_tok, vocab)\n",
        "    va_tok_u  = apply_unk(va_tok, vocab)\n",
        "\n",
        "    # train/eval for each n and smoothing\n",
        "    for n in N_ORDERS:\n",
        "        for s in smoothings_here:\n",
        "            lm = train_lm(tr_tok_u, order=n, smoothing=s)\n",
        "            metrics = corpus_perplexity(lm, va_tok_u, order=n)\n",
        "            results.append({\n",
        "                \"language\": lang,\n",
        "                \"order\": n,\n",
        "                \"smoothing\": s,\n",
        "                **metrics\n",
        "            })\n",
        "            print(f\"  n={n}  {s}: PPL={metrics['perplexity']:.2f}  CE={metrics['cross_entropy']:.4f}  tokens={metrics['tokens_counted']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3cfccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "2c3cfccd",
        "outputId": "c2b868ae-4fdf-43ed-d3e4-c193b679f85f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"en\",\n          \"te\",\n          \"ar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoothing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"laplace\",\n          \"kn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cross_entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.862129538088981,\n        \"min\": 1.7180523324754369,\n        \"max\": 9.063613108658064,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.702480746738256,\n          3.2206107226086496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1850.0048464681045,\n        \"min\": 5.5736622448725095,\n        \"max\": 8635.29461462317,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          40.54776843987683,\n          25.043410088655353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_counted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 141537,\n        \"min\": 2462,\n        \"max\": 366301,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4003,\n          2818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "res_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8dd713de-518e-444a-ba30-409b279f5bc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>order</th>\n",
              "      <th>smoothing</th>\n",
              "      <th>cross_entropy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>tokens_counted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.702481</td>\n",
              "      <td>40.547768</td>\n",
              "      <td>3588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.757217</td>\n",
              "      <td>15.755938</td>\n",
              "      <td>3588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.710260</td>\n",
              "      <td>15.033185</td>\n",
              "      <td>3588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>4.156133</td>\n",
              "      <td>63.824205</td>\n",
              "      <td>4003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.666342</td>\n",
              "      <td>14.387244</td>\n",
              "      <td>4003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ar</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.433498</td>\n",
              "      <td>11.398690</td>\n",
              "      <td>4003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>en</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>7.404704</td>\n",
              "      <td>1643.697558</td>\n",
              "      <td>363290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>en</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>5.422244</td>\n",
              "      <td>226.386513</td>\n",
              "      <td>363290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>en</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>9.063613</td>\n",
              "      <td>8635.294615</td>\n",
              "      <td>366301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>en</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>5.031582</td>\n",
              "      <td>153.175181</td>\n",
              "      <td>366301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ko</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>2.903902</td>\n",
              "      <td>18.245207</td>\n",
              "      <td>2462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ko</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.027521</td>\n",
              "      <td>7.595231</td>\n",
              "      <td>2462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ko</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.024042</td>\n",
              "      <td>7.568856</td>\n",
              "      <td>2462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ko</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.220611</td>\n",
              "      <td>25.043410</td>\n",
              "      <td>2818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ko</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>1.827958</td>\n",
              "      <td>6.221173</td>\n",
              "      <td>2818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ko</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>1.718052</td>\n",
              "      <td>5.573662</td>\n",
              "      <td>2818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>te</td>\n",
              "      <td>2</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.053345</td>\n",
              "      <td>21.186098</td>\n",
              "      <td>12658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>te</td>\n",
              "      <td>2</td>\n",
              "      <td>kn</td>\n",
              "      <td>2.643828</td>\n",
              "      <td>14.066943</td>\n",
              "      <td>12658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>te</td>\n",
              "      <td>2</td>\n",
              "      <td>wb</td>\n",
              "      <td>2.646654</td>\n",
              "      <td>14.106763</td>\n",
              "      <td>12658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>te</td>\n",
              "      <td>3</td>\n",
              "      <td>laplace</td>\n",
              "      <td>3.345450</td>\n",
              "      <td>28.373338</td>\n",
              "      <td>13042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>te</td>\n",
              "      <td>3</td>\n",
              "      <td>kn</td>\n",
              "      <td>1.961938</td>\n",
              "      <td>7.113101</td>\n",
              "      <td>13042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>te</td>\n",
              "      <td>3</td>\n",
              "      <td>wb</td>\n",
              "      <td>1.902254</td>\n",
              "      <td>6.700981</td>\n",
              "      <td>13042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dd713de-518e-444a-ba30-409b279f5bc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dd713de-518e-444a-ba30-409b279f5bc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dd713de-518e-444a-ba30-409b279f5bc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c7f537b1-01ae-4b3b-a030-bd64adfb8632\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7f537b1-01ae-4b3b-a030-bd64adfb8632')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c7f537b1-01ae-4b3b-a030-bd64adfb8632 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_582d0196-926a-432b-b16d-0ea9bda3d2c2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_582d0196-926a-432b-b16d-0ea9bda3d2c2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   language  order smoothing  cross_entropy   perplexity  tokens_counted\n",
              "0        ar      2   laplace       3.702481    40.547768            3588\n",
              "1        ar      2        kn       2.757217    15.755938            3588\n",
              "2        ar      2        wb       2.710260    15.033185            3588\n",
              "3        ar      3   laplace       4.156133    63.824205            4003\n",
              "4        ar      3        kn       2.666342    14.387244            4003\n",
              "5        ar      3        wb       2.433498    11.398690            4003\n",
              "18       en      2   laplace       7.404704  1643.697558          363290\n",
              "19       en      2        wb       5.422244   226.386513          363290\n",
              "20       en      3   laplace       9.063613  8635.294615          366301\n",
              "21       en      3        wb       5.031582   153.175181          366301\n",
              "6        ko      2   laplace       2.903902    18.245207            2462\n",
              "7        ko      2        kn       2.027521     7.595231            2462\n",
              "8        ko      2        wb       2.024042     7.568856            2462\n",
              "9        ko      3   laplace       3.220611    25.043410            2818\n",
              "10       ko      3        kn       1.827958     6.221173            2818\n",
              "11       ko      3        wb       1.718052     5.573662            2818\n",
              "12       te      2   laplace       3.053345    21.186098           12658\n",
              "13       te      2        kn       2.643828    14.066943           12658\n",
              "14       te      2        wb       2.646654    14.106763           12658\n",
              "15       te      3   laplace       3.345450    28.373338           13042\n",
              "16       te      3        kn       1.961938     7.113101           13042\n",
              "17       te      3        wb       1.902254     6.700981           13042"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res_df = pd.DataFrame(results).sort_values([\"language\",\"order\"])\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PqNPCPGv9sms",
      "metadata": {
        "id": "PqNPCPGv9sms"
      },
      "source": [
        "### POTENTIAL NEURAL MODEL ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CqYMZhk7KRw7",
      "metadata": {
        "id": "CqYMZhk7KRw7"
      },
      "outputs": [],
      "source": [
        "# If needed (Colab/new env), uncomment:\n",
        "# !pip install -q bpemb torch\n",
        "\n",
        "import math, re, random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from bpemb import BPEmb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n980Tf6kS6_0",
      "metadata": {
        "id": "n980Tf6kS6_0"
      },
      "outputs": [],
      "source": [
        "SEED      = 42\n",
        "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# training knobs (start small, bump after it works)\n",
        "EPOCHS    = 10\n",
        "BATCH     = 128\n",
        "SEQ_LEN   = 120\n",
        "EMB_DIM   = 100      # must match bpemb dim\n",
        "HIDDEN    = 256\n",
        "LAYERS    = 2\n",
        "DROPOUT   = 0.2\n",
        "LR        = 2e-3\n",
        "CLIP      = 1.0\n",
        "\n",
        "# bpemb options\n",
        "# Option A (per-language): ar/ko/te/en separately — best quality\n",
        "BPE_PER_LANGUAGE = True\n",
        "BP_VS   = 5000    # vocab size\n",
        "BP_DIM  = EMB_DIM   # should equal EMB_DIM\n",
        "\n",
        "# Option B (single multilingual model): use 'multi'\n",
        "# BPE_PER_LANGUAGE = False\n",
        "# BP_LANG = \"multi\"     # uncomment to try multilingual model\n",
        "\n",
        "# light text normalization\n",
        "LOWERCASE    = True\n",
        "FOLD_NUMBERS = True\n",
        "\n",
        "# throttle English contexts (they’re huge)\n",
        "EN_MAX_ROWS_TRAIN    = 30000\n",
        "EN_MAX_ROWS_VALID    = 5000\n",
        "EN_MAX_TOK_PER_DOC   = 400      # subword pieces per doc (for speed)\n",
        "FREEZE_EMBEDDINGS    = True     # False = fine-tune embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QZAwr540TOEO",
      "metadata": {
        "id": "QZAwr540TOEO"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-SIaeTdTPuS",
      "metadata": {
        "id": "c-SIaeTdTPuS"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\" if s is None else str(s)\n",
        "    if LOWERCASE:\n",
        "        s = s.lower()\n",
        "    if FOLD_NUMBERS:\n",
        "        s = re.sub(r\"\\d+\", \"<num>\", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def get_series(lang):\n",
        "    if lang == \"en\":\n",
        "        tr = df_train[CONTEXT_FIELD].dropna().astype(str)\n",
        "        va = df_val[CONTEXT_FIELD].dropna().astype(str)\n",
        "        if len(tr) > EN_MAX_ROWS_TRAIN:\n",
        "            tr = tr.sample(EN_MAX_ROWS_TRAIN, random_state=SEED)\n",
        "        if len(va) > EN_MAX_ROWS_VALID:\n",
        "            va = va.sample(EN_MAX_ROWS_VALID, random_state=SEED)\n",
        "        tr = tr.apply(normalize_text)\n",
        "        va = va.apply(normalize_text)\n",
        "        return tr, va, EN_MAX_TOK_PER_DOC\n",
        "    else:\n",
        "        tr = df_train[df_train[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        va = df_val[df_val[LANG_FIELD] == lang][QUESTION_FIELD].dropna().astype(str).apply(normalize_text)\n",
        "        return tr, va, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XTdgQlx4TUVo",
      "metadata": {
        "id": "XTdgQlx4TUVo"
      },
      "outputs": [],
      "source": [
        "_bp_cache = {}\n",
        "\n",
        "def load_bpemb_for_lang(lang: str):\n",
        "    if BPE_PER_LANGUAGE:\n",
        "        key = f\"{lang}:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=lang, vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "    else:\n",
        "        key = f\"multi:{BP_VS}:{BP_DIM}\"\n",
        "        if key not in _bp_cache:\n",
        "            _bp_cache[key] = BPEmb(lang=\"multi\", vs=BP_VS, dim=BP_DIM)\n",
        "        return _bp_cache[key]\n",
        "\n",
        "def build_embedding_matrix(bp: BPEmb):\n",
        "    # bp.emb.vectors shape: (vs, dim)\n",
        "    pad_vec = np.zeros((1, BP_DIM), dtype=np.float32)\n",
        "    eos_vec = np.zeros((1, BP_DIM), dtype=np.float32)  # simple; could be mean vector\n",
        "    mat = np.concatenate([bp.emb.vectors, pad_vec, eos_vec], axis=0).astype(np.float32)\n",
        "    pad_id = bp.emb.vectors.shape[0]        # PAD index\n",
        "    eos_id = bp.emb.vectors.shape[0] + 1    # EOS index\n",
        "    return torch.tensor(mat), pad_id, eos_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ISId1NZTXES",
      "metadata": {
        "id": "-ISId1NZTXES"
      },
      "outputs": [],
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d)  # list of subword ids (0..vs-1)\n",
        "        if max_len_per_doc:    # throttle long docs (esp. English)\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BwPuUPY4TYnR",
      "metadata": {
        "id": "BwPuUPY4TYnR"
      },
      "outputs": [],
      "source": [
        "def encode_docs_to_stream(bp: BPEmb, docs: List[str], eos_id: int, max_len_per_doc: int = None):\n",
        "    ids = []\n",
        "    for d in docs:\n",
        "        wp = bp.encode_ids(d)  # list of subword ids (0..vs-1)\n",
        "        if max_len_per_doc:    # throttle long docs (esp. English)\n",
        "            wp = wp[:max_len_per_doc]\n",
        "        ids.extend(wp + [eos_id])\n",
        "    return np.array(ids, dtype=np.int64)\n",
        "\n",
        "class WPStreamDataset(Dataset):\n",
        "    def __init__(self, id_stream: np.ndarray, seq_len: int):\n",
        "        self.data = torch.tensor(id_stream, dtype=torch.long)\n",
        "        self.seq_len = seq_len\n",
        "        self.num_seq = max(0, (len(self.data) - 1) // seq_len)\n",
        "\n",
        "    def __len__(self): return self.num_seq\n",
        "    def __getitem__(self, i):\n",
        "        s = i * self.seq_len\n",
        "        x = self.data[s : s+self.seq_len]\n",
        "        y = self.data[s+1 : s+1+self.seq_len]\n",
        "        return x, y\n",
        "\n",
        "def make_loaders(id_train: np.ndarray, id_valid: np.ndarray, seq_len: int, batch: int):\n",
        "    tr_ds = WPStreamDataset(id_train, seq_len)\n",
        "    va_ds = WPStreamDataset(id_valid, seq_len)\n",
        "    tr_dl = DataLoader(tr_ds, batch_size=batch, shuffle=True,  drop_last=True)\n",
        "    va_dl = DataLoader(va_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "    return tr_dl, va_dl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bw0gFkvaTbJp",
      "metadata": {
        "id": "bw0gFkvaTbJp"
      },
      "outputs": [],
      "source": [
        "class WPLSTMLM(nn.Module):\n",
        "    def __init__(self, emb_matrix: torch.Tensor, pad_id: int, hidden=256, layers=2, dropout=0.2, freeze=True):\n",
        "        super().__init__()\n",
        "        V, D = emb_matrix.shape\n",
        "        self.embed = nn.Embedding.from_pretrained(emb_matrix, freeze=freeze, padding_idx=pad_id)\n",
        "        self.lstm  = nn.LSTM(D, hidden, num_layers=layers, dropout=dropout, batch_first=True)\n",
        "        self.drop  = nn.Dropout(dropout)\n",
        "        self.head  = nn.Linear(hidden, V)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embed(x)\n",
        "        x, h = self.lstm(x, h)\n",
        "        x = self.drop(x)\n",
        "        logits = self.head(x)\n",
        "        return logits, h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AtVVDz0GTe3a",
      "metadata": {
        "id": "AtVVDz0GTe3a"
      },
      "outputs": [],
      "source": [
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_tok = 0.0, 0\n",
        "    crit = nn.CrossEntropyLoss(reduction=\"sum\")  # sum, we divide later\n",
        "    for x, y in loader:\n",
        "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "        logits, _ = model(x)\n",
        "        loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "        total_tok  += y.numel()\n",
        "    ce  = total_loss / max(total_tok, 1)   # natural log\n",
        "    ppl = math.exp(ce)\n",
        "    return ce, ppl, total_tok\n",
        "\n",
        "def train_bpemb_lm(lang, train_series, valid_series, max_tok_per_doc=None):\n",
        "    set_seed()\n",
        "    bp   = load_bpemb_for_lang(lang if BPE_PER_LANGUAGE else \"multi\")\n",
        "    embM, pad_id, eos_id = build_embedding_matrix(bp)\n",
        "\n",
        "    ids_tr = encode_docs_to_stream(bp, list(train_series), eos_id, max_tok_per_doc)\n",
        "    ids_va = encode_docs_to_stream(bp, list(valid_series), eos_id, max_tok_per_doc)\n",
        "\n",
        "    tr_dl, va_dl = make_loaders(ids_tr, ids_va, SEQ_LEN, BATCH)\n",
        "\n",
        "    model = WPLSTMLM(embM, pad_id, hidden=HIDDEN, layers=LAYERS, dropout=DROPOUT, freeze=FREEZE_EMBEDDINGS).to(DEVICE)\n",
        "    opt   = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "\n",
        "    print(f\"[{lang}] subword_vocab={embM.size(0)} train_batches={len(tr_dl)} valid_batches={len(va_dl)} device={DEVICE}\")\n",
        "\n",
        "    best = float(\"inf\")\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total, steps = 0.0, 0\n",
        "        crit = nn.CrossEntropyLoss()\n",
        "        for x, y in tr_dl:\n",
        "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits, _ = model(x)\n",
        "            loss = crit(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "            opt.step()\n",
        "            total += loss.item(); steps += 1\n",
        "        sched.step()\n",
        "        ce, ppl, tok = evaluate(model, va_dl)\n",
        "        best = min(best, ppl)\n",
        "        print(f\"  epoch {ep:02d}  train_ce={total/max(steps,1):.4f}  val_ce={ce:.4f}  val_ppl={ppl:.2f}  tokens={tok}\")\n",
        "    return best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MoOHavS7TiN0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoOHavS7TiN0",
        "outputId": "bce0c746-4535-4a93-e810-ff683352263d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "▶ BPEmb LSTM on ar: train_rows=2558 valid_rows=415\n",
            "[ar] subword_vocab=25002 train_batches=3 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=10.0721  val_ce=9.7612  val_ppl=17347.82  tokens=4080\n",
            "  epoch 02  train_ce=8.9951  val_ce=7.9363  val_ppl=2796.89  tokens=4080\n",
            "  epoch 03  train_ce=7.4374  val_ce=7.3163  val_ppl=1504.69  tokens=4080\n",
            "  epoch 04  train_ce=6.8752  val_ce=7.2103  val_ppl=1353.33  tokens=4080\n",
            "  epoch 05  train_ce=6.7198  val_ce=7.2457  val_ppl=1402.10  tokens=4080\n",
            "  epoch 06  train_ce=6.7010  val_ce=7.2711  val_ppl=1438.09  tokens=4080\n",
            "  epoch 07  train_ce=6.6713  val_ce=7.2776  val_ppl=1447.47  tokens=4080\n",
            "  epoch 08  train_ce=6.6410  val_ce=7.2752  val_ppl=1444.05  tokens=4080\n",
            "  epoch 09  train_ce=6.6239  val_ce=7.2728  val_ppl=1440.52  tokens=4080\n",
            "  epoch 10  train_ce=6.6241  val_ce=7.2719  val_ppl=1439.28  tokens=4080\n",
            "\n",
            "▶ BPEmb LSTM on ko: train_rows=2422 valid_rows=356\n",
            "[ko] subword_vocab=25002 train_batches=3 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=10.0542  val_ce=9.6000  val_ppl=14764.87  tokens=3960\n",
            "  epoch 02  train_ce=8.6971  val_ce=7.4407  val_ppl=1704.02  tokens=3960\n",
            "  epoch 03  train_ce=6.9107  val_ce=6.6034  val_ppl=737.63  tokens=3960\n",
            "  epoch 04  train_ce=6.2024  val_ce=6.4381  val_ppl=625.20  tokens=3960\n",
            "  epoch 05  train_ce=6.0507  val_ce=6.4997  val_ppl=664.95  tokens=3960\n",
            "  epoch 06  train_ce=6.0422  val_ce=6.5258  val_ppl=682.53  tokens=3960\n",
            "  epoch 07  train_ce=6.0122  val_ce=6.5230  val_ppl=680.60  tokens=3960\n",
            "  epoch 08  train_ce=5.9818  val_ce=6.5120  val_ppl=673.17  tokens=3960\n",
            "  epoch 09  train_ce=5.9696  val_ce=6.5058  val_ppl=669.01  tokens=3960\n",
            "  epoch 10  train_ce=5.9723  val_ce=6.5040  val_ppl=667.82  tokens=3960\n",
            "\n",
            "▶ BPEmb LSTM on te: train_rows=1355 valid_rows=384\n",
            "[te] subword_vocab=25002 train_batches=1 valid_batches=1 device=cuda\n",
            "  epoch 01  train_ce=10.1187  val_ce=10.0712  val_ppl=23651.35  tokens=3720\n",
            "  epoch 02  train_ce=10.0653  val_ce=9.9850  val_ppl=21699.44  tokens=3720\n",
            "  epoch 03  train_ce=9.9706  val_ce=9.7349  val_ppl=16897.39  tokens=3720\n",
            "  epoch 04  train_ce=9.6934  val_ce=9.0935  val_ppl=8897.66  tokens=3720\n",
            "  epoch 05  train_ce=8.9793  val_ce=8.4767  val_ppl=4801.39  tokens=3720\n",
            "  epoch 06  train_ce=8.2832  val_ce=8.1013  val_ppl=3298.72  tokens=3720\n",
            "  epoch 07  train_ce=7.8434  val_ce=7.8963  val_ppl=2687.42  tokens=3720\n",
            "  epoch 08  train_ce=7.6036  val_ce=7.7845  val_ppl=2403.17  tokens=3720\n",
            "  epoch 09  train_ce=7.4619  val_ce=7.7338  val_ppl=2284.25  tokens=3720\n",
            "  epoch 10  train_ce=7.4238  val_ce=7.7207  val_ppl=2254.62  tokens=3720\n",
            "\n",
            "▶ BPEmb LSTM on en: train_rows=15343 valid_rows=3011\n",
            "[en] subword_vocab=25002 train_batches=284 valid_batches=57 device=cuda\n",
            "  epoch 01  train_ce=6.9745  val_ce=6.5458  val_ppl=696.30  tokens=436320\n",
            "  epoch 02  train_ce=6.3183  val_ce=6.0733  val_ppl=434.11  tokens=436320\n",
            "  epoch 03  train_ce=6.0007  val_ce=5.8299  val_ppl=340.31  tokens=436320\n",
            "  epoch 04  train_ce=5.8001  val_ce=5.6766  val_ppl=291.97  tokens=436320\n",
            "  epoch 05  train_ce=5.6617  val_ce=5.5634  val_ppl=260.72  tokens=436320\n",
            "  epoch 06  train_ce=5.5615  val_ce=5.4849  val_ppl=241.04  tokens=436320\n",
            "  epoch 07  train_ce=5.4915  val_ce=5.4337  val_ppl=229.00  tokens=436320\n",
            "  epoch 08  train_ce=5.4436  val_ce=5.3997  val_ppl=221.34  tokens=436320\n",
            "  epoch 09  train_ce=5.4106  val_ce=5.3833  val_ppl=217.73  tokens=436320\n",
            "  epoch 10  train_ce=5.3946  val_ce=5.3782  val_ppl=216.64  tokens=436320\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'language': 'ar', 'model': 'bpemb_lstm', 'best_ppl': 1353.3297535724187},\n",
              " {'language': 'ko', 'model': 'bpemb_lstm', 'best_ppl': 625.1960137316046},\n",
              " {'language': 'te', 'model': 'bpemb_lstm', 'best_ppl': 2254.6223761306815},\n",
              " {'language': 'en', 'model': 'bpemb_lstm', 'best_ppl': 216.63805851503267}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bpemb_results = []\n",
        "for lang in LANGUAGES:\n",
        "    tr, va, max_len = get_series(lang)\n",
        "    print(f\"\\n▶ BPEmb LSTM on {lang}: train_rows={len(tr)} valid_rows={len(va)}\")\n",
        "    best_ppl = train_bpemb_lm(lang if lang!=\"en\" else \"en\", tr, va, max_tok_per_doc=max_len)\n",
        "    bpemb_results.append({\"language\": lang, \"model\": \"bpemb_lstm\", \"best_ppl\": best_ppl})\n",
        "\n",
        "bpemb_results\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
