{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2a21598",
      "metadata": {
        "id": "b2a21598"
      },
      "source": [
        "# WEEK 37\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q camel-tools konlpy indic-nlp-library\n",
        "!apt -y install default-jdk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lprgdS0lp3C8",
        "outputId": "c35a48db-1b1e-4029-ade6-18d1a7a82635"
      },
      "id": "lprgdS0lp3C8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m146.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  default-jdk-headless default-jre default-jre-headless fonts-dejavu-core\n",
            "  fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-11-jdk openjdk-11-jre x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-11-demo openjdk-11-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  default-jdk default-jdk-headless default-jre default-jre-headless\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-11-jdk\n",
            "  openjdk-11-jre x11-utils\n",
            "0 upgraded, 14 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 5,373 kB of archives.\n",
            "After this operation, 15.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.28+6-1ubuntu1~22.04.1 [214 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk-headless amd64 2:1.11-72build2 [942 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.28+6-1ubuntu1~22.04.1 [1,342 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk amd64 2:1.11-72build2 [908 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Fetched 5,373 kB in 3s (2,118 kB/s)\n",
            "Selecting previously unselected package default-jre-headless.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../00-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre-headless (2:1.11-72build2) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../02-openjdk-11-jre_11.0.28+6-1ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package default-jre.\n",
            "Preparing to unpack .../03-default-jre_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jre (2:1.11-72build2) ...\n",
            "Selecting previously unselected package default-jdk-headless.\n",
            "Preparing to unpack .../04-default-jdk-headless_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jdk-headless (2:1.11-72build2) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../05-openjdk-11-jdk_11.0.28+6-1ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package default-jdk.\n",
            "Preparing to unpack .../06-default-jdk_2%3a1.11-72build2_amd64.deb ...\n",
            "Unpacking default-jdk (2:1.11-72build2) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../07-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../08-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../09-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../10-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../11-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../12-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../13-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up default-jre-headless (2:1.11-72build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
            "Setting up default-jre (2:1.11-72build2) ...\n",
            "Setting up default-jdk-headless (2:1.11-72build2) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up openjdk-11-jdk:amd64 (11.0.28+6-1ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up default-jdk (2:1.11-72build2) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, pandas as pd, nltk\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import Laplace, KneserNeyInterpolated, WittenBellInterpolated\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize # Arabic\n",
        "from konlpy.tag import Okt # Korean\n",
        "from indicnlp.tokenize import indic_tokenize # Telugu\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt'); nltk.download('punkt_tab')\n",
        "\n",
        "okt = Okt() # for Korean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vdaTFrTpwISh",
        "outputId": "8ca63501-e098-42fa-a0ac-ae0df6cab074"
      },
      "id": "vdaTFrTpwISh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
        "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
        "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
        "\n",
        "QUESTION, CONTEXT, LANG = \"question\", \"context\", \"lang\"\n",
        "LANGUAGES = [\"ar\", \"ko\", \"te\", \"en\"]\n",
        "Ns = [2, 3]\n",
        "SMOOTHINGS = [\"laplace\", \"kn\", \"wb\"]\n",
        "\n",
        "# tokenizers per language\n",
        "def select_tokenizer(lang):\n",
        "    if lang == \"ar\":\n",
        "        return simple_word_tokenize\n",
        "    if lang == \"ko\":\n",
        "        return okt.morphs\n",
        "    if lang == \"te\":\n",
        "        return lambda s: list(indic_tokenize.trivial_tokenize(s))\n",
        "    if lang == \"en\":\n",
        "        return nltk.word_tokenize\n",
        "\n",
        "def tokenize_column(series, lang):\n",
        "    tokenize = select_tokenizer(lang)\n",
        "    return [tokenize(str(x).lower()) for x in series.dropna()]\n",
        "\n",
        "def build_vocab(tokenized, min_freq):\n",
        "    counter = Counter(w for s in tokenized for w in s)\n",
        "    vocab = {w:i for i,(w,c) in enumerate(counter.items()) if c >= min_freq}\n",
        "    vocab[\"<OOV>\"] = len(vocab)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "# replace all tokens that are not part of the vocab with <OOV> token\n",
        "def apply_oov(tokenized, vocab):\n",
        "    return [[w if w in vocab else \"<OOV>\" for w in s] for s in tokenized]\n",
        "\n",
        "def train_lm(tokenized, n, smoothing):\n",
        "    train_grams, vocab = padded_everygram_pipeline(n, tokenized)\n",
        "    if smoothing == \"laplace\":\n",
        "      model = Laplace(n)\n",
        "    elif smoothing == \"kn\":\n",
        "      model = KneserNeyInterpolated(n)\n",
        "    elif smoothing == \"wb\":\n",
        "      model = WittenBellInterpolated(n)\n",
        "    else:\n",
        "      raise ValueError(smoothing)\n",
        "    model.fit(train_grams, vocab)\n",
        "\n",
        "    return model\n",
        "\n",
        "# calculate perplexity\n",
        "def perplexity(model, tokenized_sentences, n):\n",
        "    sum_log_probs = 0.0\n",
        "    count_ngrams = 0\n",
        "    for sentence in tokenized_sentences:\n",
        "        for ngram in ngrams(list(pad_both_ends(sentence, n=n)), n):\n",
        "            context, w = ngram[:-1], ngram[-1]\n",
        "            prob = model.score(w, context) or 1e-12\n",
        "            sum_log_probs += math.log(prob); count_ngrams += 1\n",
        "    cross_entropy = - sum_log_probs / max(count_ngrams, 1)\n",
        "\n",
        "    return math.exp(cross_entropy), cross_entropy, count_ngrams\n",
        "\n",
        "# train and evaluate\n",
        "rows = []\n",
        "for L in LANGUAGES:\n",
        "    if L == \"en\":\n",
        "        tr_txt = df_tr[CONTEXT]\n",
        "        val_txt = df_va[CONTEXT]\n",
        "        smooths = [s for s in SMOOTHINGS if s != \"kn\"]  # leave out KN for english (copmutational issue)\n",
        "    else:\n",
        "        tr_txt = df_tr.loc[df_tr[LANG]==L, QUESTION]\n",
        "        val_txt = df_va.loc[df_va[LANG]==L, QUESTION]\n",
        "        smooths = SMOOTHINGS\n",
        "\n",
        "    tr_tok = tokenize_column(tr_txt, L)\n",
        "    val_tok = tokenize_column(val_txt, L)\n",
        "    vocab = build_vocab(tr_tok, 3)\n",
        "    tr_tok = apply_oov(tr_tok, vocab)\n",
        "    val_tok = apply_oov(val_tok, vocab)\n",
        "\n",
        "    for n in Ns:\n",
        "        for s in smooths:\n",
        "            model = train_lm(tr_tok, n, s)\n",
        "            ppl, cross_entropy, num_tokens = perplexity(model, val_tok, n)\n",
        "            rows.append(dict(language=L, order=n, smoothing=s, vocab_size=len(vocab), tokens=num_tokens, perplexity=round(ppl, 2), cross_entropy=round(cross_entropy, 4)))\n",
        "            print(f\"{L} n={n} {s}: PPL={ppl:.2f} CE={cross_entropy:.4f}\")\n",
        "\n",
        "res_df = pd.DataFrame(rows).sort_values([\"language\",\"order\",\"smoothing\"])\n",
        "print(res_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esd8lJoepMxp",
        "outputId": "da8da60f-1cb3-4689-887c-e582ce983f19"
      },
      "id": "Esd8lJoepMxp",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ar n=2 laplace: PPL=34.56 CE=3.5428\n",
            "ar n=2 kn: PPL=13.23 CE=2.5825\n",
            "ar n=2 wb: PPL=12.83 CE=2.5519\n",
            "ar n=3 laplace: PPL=54.72 CE=4.0023\n",
            "ar n=3 kn: PPL=12.03 CE=2.4878\n",
            "ar n=3 wb: PPL=9.78 CE=2.2801\n",
            "ko n=2 laplace: PPL=30.41 CE=3.4148\n",
            "ko n=2 kn: PPL=11.89 CE=2.4756\n",
            "ko n=2 wb: PPL=11.51 CE=2.4429\n",
            "ko n=3 laplace: PPL=49.59 CE=3.9037\n",
            "ko n=3 kn: PPL=9.71 CE=2.2728\n",
            "ko n=3 wb: PPL=8.16 CE=2.0992\n",
            "te n=2 laplace: PPL=30.61 CE=3.4214\n",
            "te n=2 kn: PPL=10.99 CE=2.3966\n",
            "te n=2 wb: PPL=10.89 CE=2.3879\n",
            "te n=3 laplace: PPL=43.59 CE=3.7747\n",
            "te n=3 kn: PPL=8.54 CE=2.1443\n",
            "te n=3 wb: PPL=7.28 CE=1.9854\n",
            "en n=2 laplace: PPL=1508.92 CE=7.3192\n",
            "en n=2 wb: PPL=209.77 CE=5.3460\n",
            "en n=3 laplace: PPL=8069.52 CE=8.9958\n",
            "en n=3 wb: PPL=146.71 CE=4.9885\n",
            "   language  order smoothing  vocab_size  tokens  perplexity  cross_entropy\n",
            "1        ar      2        kn         965    3457       13.23         2.5825\n",
            "0        ar      2   laplace         965    3457       34.56         3.5428\n",
            "2        ar      2        wb         965    3457       12.83         2.5519\n",
            "4        ar      3        kn         965    3872       12.03         2.4878\n",
            "3        ar      3   laplace         965    3872       54.72         4.0023\n",
            "5        ar      3        wb         965    3872        9.78         2.2801\n",
            "18       en      2   laplace       29119  353455     1508.92         7.3192\n",
            "19       en      2        wb       29119  353455      209.77         5.3460\n",
            "20       en      3   laplace       29119  356466     8069.52         8.9958\n",
            "21       en      3        wb       29119  356466      146.71         4.9885\n",
            "7        ko      2        kn         755    3608       11.89         2.4756\n",
            "6        ko      2   laplace         755    3608       30.41         3.4148\n",
            "8        ko      2        wb         755    3608       11.51         2.4429\n",
            "10       ko      3        kn         755    3964        9.71         2.2728\n",
            "9        ko      3   laplace         755    3964       49.59         3.9037\n",
            "11       ko      3        wb         755    3964        8.16         2.0992\n",
            "13       te      2        kn         479    3074       10.99         2.3966\n",
            "12       te      2   laplace         479    3074       30.61         3.4214\n",
            "14       te      2        wb         479    3074       10.89         2.3879\n",
            "16       te      3        kn         479    3458        8.54         2.1443\n",
            "15       te      3   laplace         479    3458       43.59         3.7747\n",
            "17       te      3        wb         479    3458        7.28         1.9854\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}