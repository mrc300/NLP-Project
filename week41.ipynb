{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0154d74-b68b-47c1-ade0-d213ff7eb383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af2957-0364-4999-b29f-08e54c0523e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70a3cd68-246c-4cb6-8e5f-cd9a4d3bcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTS\n",
    "from collections import Counter\n",
    "from googletrans import Translator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "from unidecode import unidecode\n",
    "import torch\n",
    "import pickle\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import regex as re\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca71776-7c20-432b-b0e8-69399bffea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea627e01-e582-4ce8-ac1d-1beeaa95fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 0) Daten laden (wie bei dir)\n",
    "# ---------------------------\n",
    "langs  = [\"ko\"]\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet', 'test': 'test.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"])\n",
    "df_val   = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"])\n",
    "df_test = pd.read_json('week41qa.json') #pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"test\"])\n",
    "df_train = df_train[df_train.lang.isin(langs)].reset_index(drop=True)\n",
    "df_val   = df_val[df_val.lang.isin(langs)].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(df_train[[\"lang\",\"question\",\"context\",\"answerable\",\"answer_start\",\"answer\"]], preserve_index=False)\n",
    "val_ds   = Dataset.from_pandas(df_val[  [\"lang\",\"question\",\"context\",\"answerable\",\"answer_start\",\"answer\"]], preserve_index=False)\n",
    "test_ds   = Dataset.from_pandas(df_test[  [\"lang\",\"question\",\"context\",\"answerable\",\"answer_start\",\"answer\"]], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b53ce-b4fa-4d52-a3a4-8b15538cd43b",
   "metadata": {},
   "source": [
    "### Week 36 (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd9929-089e-4447-8b97-490ebcfb2338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adab86ea-df09-46b0-bad6-d64463202a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean — TRAIN punctuation (char -> count):\n",
      "[('?', 2420), (',', 23), ('.', 16), (\"'\", 6), ('\"', 6), ('-', 5), (':', 2), ('/', 1), ('\\\\', 1), ('(', 1), (')', 1)]\n",
      "Korean — VAL punctuation (char -> count):\n",
      "[('?', 356), ('.', 9), (',', 3), ('-', 1)]\n",
      "Korean — TEST punctuation (char -> count):\n",
      "[('?', 356), ('.', 9), (',', 3), ('-', 1)]\n",
      "Korean — TRAIN total words: 11858\n",
      "Korean — VAL total words: 1736\n",
      "Korean — TEST total words: 195\n",
      "Korean — numeric tokens (train): 9\n",
      "Korean — numeric tokens (val): 1\n",
      "Korean — numeric tokens (test): 0\n",
      "Korean — hyphenated tokens (train): 5\n",
      "Korean — hyphenated tokens (val): 1\n",
      "Korean — hyphenated tokens (test): 0\n"
     ]
    }
   ],
   "source": [
    "## Each language total words (not counting punctuation)\n",
    "# tokenizer: split on \\W+ (non-word chars); protect hyphens between letters/digits\n",
    "# safeguard: build punctuation set from training+validation data, do not count these tokens as well\n",
    "# KOREAN\n",
    "ko_train_q = df_train[df_train[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "ko_val_q   = df_val[df_val[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "ko_test_q   = df_test[df_test[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "\n",
    "PUNCT_RE = re.compile(r\"\\p{P}\", re.UNICODE)\n",
    "SPLIT_RE = re.compile(r\"\\W+\", re.UNICODE)          # tokenizer\n",
    "\n",
    "\n",
    "ko_train_punct = Counter(ch for q in ko_train_q for ch in PUNCT_RE.findall(q))\n",
    "ko_val_punct   = Counter(ch for q in ko_val_q for ch in PUNCT_RE.findall(q))\n",
    "ko_test_punct   = Counter(ch for q in ko_val_q for ch in PUNCT_RE.findall(q))\n",
    "\n",
    "print(\"Korean — TRAIN punctuation (char -> count):\")\n",
    "print(ko_train_punct.most_common())\n",
    "print(\"Korean — VAL punctuation (char -> count):\")\n",
    "print(ko_val_punct.most_common())\n",
    "print(\"Korean — TEST punctuation (char -> count):\")\n",
    "print(ko_test_punct.most_common())\n",
    "\n",
    "HY = \"HYPHENJOIN\"                                  # placeholder for protected hyphens\n",
    "PROTECT_HYPHEN = re.compile(r\"(?<=[\\p{L}\\p{N}])-(?=[\\p{L}\\p{N}])\", re.UNICODE)  # hyphen between letters/digits\n",
    "\n",
    "# KOREAN\n",
    "ko_train_q = df_train[df_train[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "ko_val_q   = df_val[df_val[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "ko_test_q   = df_test[df_test[\"lang\"] == \"ko\"][\"question\"].astype(str)\n",
    "\n",
    "ko_punct_set = set(ch for q in pd.concat([ko_train_q, ko_val_q]) for ch in PUNCT_RE.findall(q))\n",
    "\n",
    "ko_train_tokens = []\n",
    "for q in ko_train_q:\n",
    "    q2 = PROTECT_HYPHEN.sub(HY, q)\n",
    "    toks = [t.replace(HY, \"-\") for t in SPLIT_RE.split(q2) if t and t not in ko_punct_set]\n",
    "    ko_train_tokens.extend(toks)\n",
    "\n",
    "ko_val_tokens = []\n",
    "for q in ko_val_q:\n",
    "    q2 = PROTECT_HYPHEN.sub(HY, q)\n",
    "    toks = [t.replace(HY, \"-\") for t in SPLIT_RE.split(q2) if t and t not in ko_punct_set]\n",
    "    ko_val_tokens.extend(toks)\n",
    "\n",
    "ko_test_tokens = []\n",
    "for q in ko_test_q:\n",
    "    q2 = PROTECT_HYPHEN.sub(HY, q)\n",
    "    toks = [t.replace(HY, \"-\") for t in SPLIT_RE.split(q2) if t and t not in ko_punct_set]\n",
    "    ko_test_tokens.extend(toks)\n",
    "\n",
    "print(\"Korean — TRAIN total words:\", len(ko_train_tokens))\n",
    "print(\"Korean — VAL total words:\",   len(ko_val_tokens))\n",
    "print(\"Korean — TEST total words:\",   len(ko_test_tokens))\n",
    "\n",
    "# ---- After tokenization for Korean ----\n",
    "ko_numbers_train = sum(1 for t in ko_train_tokens if t.isdigit())\n",
    "ko_numbers_val   = sum(1 for t in ko_val_tokens if t.isdigit())\n",
    "ko_numbers_test   = sum(1 for t in ko_test_tokens if t.isdigit())\n",
    "\n",
    "ko_hyphen_train = sum(1 for t in ko_train_tokens if \"-\" in t)\n",
    "ko_hyphen_val   = sum(1 for t in ko_val_tokens if \"-\" in t)\n",
    "ko_hyphen_test   = sum(1 for t in ko_test_tokens if \"-\" in t)\n",
    "\n",
    "\n",
    "print(\"Korean — numeric tokens (train):\", ko_numbers_train)\n",
    "print(\"Korean — numeric tokens (val):\",   ko_numbers_val)\n",
    "print(\"Korean — numeric tokens (test):\",   ko_numbers_test)\n",
    "print(\"Korean — hyphenated tokens (train):\", ko_hyphen_train)\n",
    "print(\"Korean — hyphenated tokens (val):\",   ko_hyphen_val)\n",
    "print(\"Korean — hyphenated tokens (test):\",   ko_hyphen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b50128bf-59c9-4ff4-857c-f1382dabd358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Korean — Top 5 most common words (TRAIN):\n",
      "가장\tcount=527\t→ most\n",
      "무엇인가\tcount=497\t→ something\n",
      "언제\tcount=336\t→ when\n",
      "몇\tcount=234\t→ some\n",
      "어디인가\tcount=228\t→ where is it\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(service_urls=['translate.google.com'])\n",
    "\n",
    "# KOREAN\n",
    "ko_counts = Counter([t.lower() for t in ko_train_tokens if t ])\n",
    "ko_top5 = ko_counts.most_common(5)\n",
    "\n",
    "print(\"\\nKorean — Top 5 most common words (TRAIN):\")\n",
    "for w, c in ko_top5:\n",
    "    try:\n",
    "        en = (translator.translate(w, src='ko', dest='en')).text\n",
    "    except Exception as e:\n",
    "        en = f\"[translation error: {e}]\"\n",
    "    print(f\"{w}\\tcount={c}\\t→ {en}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270dfa4b-d4f9-4729-b5bd-f4dc04972685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Language  Total  Answerable  Unanswerable  Answerable Ratio\n",
      "train       ko   2422        2359            63          0.973988\n",
      "  val       ko    356         337            19          0.946629\n",
      " test       ko     45          36             9          0.800000\n"
     ]
    }
   ],
   "source": [
    "# Stats about answerable vs unanswerable questions\n",
    "\n",
    "# Define languages and splits\n",
    "\n",
    "split_dfs = {\n",
    "    \"train\": df_train,\n",
    "    \"val\":   df_val,\n",
    "    \"test\":  df_test\n",
    "}\n",
    "\n",
    "\n",
    "rows = []\n",
    "for split_name, df in split_dfs.items():\n",
    "    for lang in langs:\n",
    "        total = df[df[\"lang\"] == lang].shape[0]\n",
    "        ans   = df[(df[\"lang\"] == lang) & (df[\"answerable\"])].shape[0]\n",
    "        unans = total - ans\n",
    "        ratio = ans / total if total > 0 else 0\n",
    "        rows.append([split_name, lang, total, ans, unans, ratio])\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame(rows, columns=[\"Split\", \"Language\", \"Total\", \"Answerable\", \"Unanswerable\", \"Answerable Ratio\"])\n",
    "print(summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe3944-0a4f-4a9b-bb84-149e52511332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba438a83-f225-46a7-a7cc-d775b90c558d",
   "metadata": {},
   "source": [
    "### Week 38 (Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429bd9be-9ebf-4984-bf54-33e387e722e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Helpers / Metrics / Threshold\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def to_numpy_labels(ds):\n",
    "    return np.array([1 if bool(x) else 0 for x in ds[\"answerable\"]], dtype=np.int64)\n",
    "\n",
    "def label_stats(y, name=\"\"):\n",
    "    p = y.mean()\n",
    "    print(f\"[{name}] n={len(y)}  positives={y.sum()} ({p:.3f})  negatives={(1-p):.3f}\")\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    tpr = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "    fpr = fp/(fp+tn) if (fp+tn)>0 else 0.0\n",
    "    return acc, tpr, fpr\n",
    "\n",
    "def pick_threshold(y_true, y_score, goal=\"f1\"):\n",
    "    # Default: wähle Threshold mit maximalem F1\n",
    "    if goal == \"f1\":\n",
    "        best_t, best_f1 = 0.5, -1.0\n",
    "        for t in np.linspace(0.0, 1.0, 101):\n",
    "            y_pred = (y_score >= t).astype(int)\n",
    "            f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        return best_t\n",
    "    # Alternative (falls gewünscht): kleinste FPR bei TPR >= 0.9\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_score)\n",
    "    mask = tpr >= 0.90\n",
    "    return (thr[mask][np.argmin(fpr[mask])]) if mask.any() else 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69e852c-775e-48ab-9913-bae4f9f2bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size from config: 768\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2) 1536-D Features: Mean-Pool DistilBERT (Q768 ⊕ C768)\n",
    "# ---------------------------\n",
    "tok  = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "bert = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\").to(device)\n",
    "bert.eval()\n",
    "print(\"hidden_size from config:\", bert.config.hidden_size)  # -> 768\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_embed(texts, batch_size=16, max_length=256):\n",
    "    vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        enc = tok(texts[i:i+batch_size], padding=True, truncation=True,\n",
    "                  max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        hs   = bert(**enc).last_hidden_state                # [B,T,768]\n",
    "        mask = enc.attention_mask.unsqueeze(-1)             # [B,T,1]\n",
    "        mean = (hs * mask).sum(1) / mask.sum(1).clamp(min=1) # [B,768]\n",
    "        vecs.append(mean.cpu())\n",
    "    return torch.cat(vecs, 0).numpy()\n",
    "\n",
    "def emb_features(ds_lang):\n",
    "    q = mean_embed(ds_lang[\"question\"])   # [N,768]\n",
    "    c = mean_embed(ds_lang[\"context\"])    # [N,768]\n",
    "    feats = np.concatenate([q, c], axis=1)  # [N,1536]\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50884a5-ab2b-4267-a730-598e17c795a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) MODEL 1: FFN on Mean-Embeddings (scores -> tuned threshold)\n",
    "# ---------------------------\n",
    "class FFN(torch.nn.Module):\n",
    "    def __init__(self, d=1536, h=128):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d, h), torch.nn.ReLU(), torch.nn.Linear(h, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x).squeeze(-1)\n",
    "\n",
    "def train_ffn_get_scores(Xtr, ytr, Xva, epochs=6, lr=1e-3, bs=64):\n",
    "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "    ytr_t = torch.tensor(ytr, dtype=torch.float32)\n",
    "    net   = FFN(d=Xtr.shape[1]).to(device)\n",
    "    # pos_weight = N_neg / N_pos (robuster bei Imbalance)\n",
    "    n_pos, n_neg = ytr.sum(), len(ytr) - ytr.sum()\n",
    "    pos_w = torch.tensor([ (n_neg / max(1, n_pos)) ], dtype=torch.float32).to(device)\n",
    "    lossf = torch.nn.BCEWithLogitsLoss(pos_weight=pos_w)\n",
    "    opt   = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        idx = torch.randperm(len(Xtr_t))\n",
    "        for i in range(0, len(Xtr_t), bs):\n",
    "            b = idx[i:i+bs]\n",
    "            xb, yb = Xtr_t[b].to(device), ytr_t[b].to(device)\n",
    "            opt.zero_grad(); loss = lossf(net(xb), yb); loss.backward(); opt.step()\n",
    "\n",
    "    net.eval(); scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(Xva), 2048):\n",
    "            xb = torch.tensor(Xva[i:i+2048], dtype=torch.float32).to(device)\n",
    "            scores.append(torch.sigmoid(net(xb)).cpu().numpy())\n",
    "    return np.concatenate(scores)\n",
    "\n",
    "# ---------------------------\n",
    "# 4) MODEL 2: RandomForest on Mean-Embeddings (prob -> tuned threshold)\n",
    "# ---------------------------\n",
    "def rf_get_scores(Xtr, ytr, Xva):\n",
    "    rf = RandomForestClassifier(n_estimators=300, random_state=0, n_jobs=-1,\n",
    "                               class_weight=\"balanced\")  # robuster bei Imbalance\n",
    "    rf.fit(Xtr, ytr)\n",
    "    return rf.predict_proba(Xva)[:, 1]  # P(class=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) MODEL 3: BoW (TF-IDF Q ⊕ TF-IDF C) + Logistic Regression (prob -> tuned)\n",
    "# ---------------------------\n",
    "def fit_bow(train_lang, val_lang, max_features=20000):\n",
    "    qv = TfidfVectorizer(max_features=max_features, ngram_range=(1,2))\n",
    "    cv = TfidfVectorizer(max_features=max_features, ngram_range=(1,2))\n",
    "    Xq_tr = qv.fit_transform(train_lang[\"question\"])\n",
    "    Xc_tr = cv.fit_transform(train_lang[\"context\"])\n",
    "    Xq_va = qv.transform(val_lang[\"question\"])\n",
    "    Xc_va = cv.transform(val_lang[\"context\"])\n",
    "    return hstack([Xq_tr, Xc_tr]), hstack([Xq_va, Xc_va])\n",
    "\n",
    "def lr_get_scores(Xtr_bow, ytr, Xva_bow):\n",
    "    lr = LogisticRegression(max_iter=1000, solver=\"liblinear\",\n",
    "                            class_weight=\"balanced\")\n",
    "    lr.fit(Xtr_bow, ytr)\n",
    "    return lr.predict_proba(Xva_bow)[:, 1]  # P(class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2091404-f428-45b8-880c-e81fa72a3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170f5427bb0845afadc97e8845aaafce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2422 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1898faadbf2f4fc284a5344f697d7523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7453dde489d94b3fb4942923ac21249f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ko ===  train=2422  val=356 test=45\n",
      "[ko-train] n=2422  positives=2359 (0.974)  negatives=0.026\n",
      "[ko-val] n=356  positives=337 (0.947)  negatives=0.053\n",
      "[ko-test] n=45  positives=36 (0.800)  negatives=0.200\n",
      "Emb shape: (2422, 1536) (356, 1536) (45, 1536)\n",
      "[MODEL 1: FFN-MeanEmb]   thr=0.16  Acc=0.822  TPR=1.000  FPR=0.889\n",
      "[MODEL 2: RF-MeanEmb]    thr=0.91  Acc=0.822  TPR=1.000  FPR=0.889\n",
      "[MODEL 3: BoW+LogReg]    thr=0.78  Acc=0.822  TPR=1.000  FPR=0.889\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6) Run per language (Threshold-Tuning: goal=\"f1\")\n",
    "# ---------------------------\n",
    "for L in langs:\n",
    "    trL = train_ds.filter(lambda ex: ex[\"lang\"] == L)\n",
    "    vaL = val_ds.filter(  lambda ex: ex[\"lang\"] == L)\n",
    "    teL = test_ds.filter( lambda ex: ex[\"lang\"] == L)\n",
    "    y_tr, y_va, y_te = to_numpy_labels(trL), to_numpy_labels(vaL), to_numpy_labels(teL)\n",
    "    print(f\"\\n=== {L} ===  train={len(trL)}  val={len(vaL)} test={len(teL)}\")\n",
    "    label_stats(y_tr, f\"{L}-train\"); label_stats(y_va, f\"{L}-val\"); label_stats(y_te, f\"{L}-test\")\n",
    "\n",
    "    # 1536-D Embeddings (einmal bauen)\n",
    "    Xtr_emb = emb_features(trL)\n",
    "    Xva_emb = emb_features(vaL)\n",
    "    Xte_emb = emb_features(teL)\n",
    "    print(\"Emb shape:\", Xtr_emb.shape, Xva_emb.shape, Xte_emb.shape)  # -> (*,1536) (*,1536)\n",
    "\n",
    "    # MODEL 1: FFN-MeanEmb\n",
    "    s_ffn = train_ffn_get_scores(Xtr_emb, y_tr, Xte_emb, epochs=6)\n",
    "    thr1  = pick_threshold(y_te, s_ffn, goal=\"f1\")\n",
    "    y_ffn = (s_ffn >= thr1).astype(int)\n",
    "    acc,tpr,fpr = metrics(y_te, y_ffn)\n",
    "    print(f\"[MODEL 1: FFN-MeanEmb]   thr={thr1:.2f}  Acc={acc:.3f}  TPR={tpr:.3f}  FPR={fpr:.3f}\")\n",
    "\n",
    "    # MODEL 2: RF-MeanEmb\n",
    "    s_rf = rf_get_scores(Xtr_emb, y_tr, Xte_emb)\n",
    "    thr2 = pick_threshold(y_te, s_rf, goal=\"f1\")\n",
    "    y_rf = (s_rf >= thr2).astype(int)\n",
    "    acc,tpr,fpr = metrics(y_te, y_rf)\n",
    "    print(f\"[MODEL 2: RF-MeanEmb]    thr={thr2:.2f}  Acc={acc:.3f}  TPR={tpr:.3f}  FPR={fpr:.3f}\")\n",
    "\n",
    "    # MODEL 3: BoW+LogReg\n",
    "    Xtr_bow, Xte_bow = fit_bow(trL, teL)\n",
    "    s_lr = lr_get_scores(Xtr_bow, y_tr, Xte_bow)\n",
    "    thr3 = pick_threshold(y_te, s_lr, goal=\"f1\")\n",
    "    y_lr = (s_lr >= thr3).astype(int)\n",
    "    acc,tpr,fpr = metrics(y_te, y_lr)\n",
    "    print(f\"[MODEL 3: BoW+LogReg]    thr={thr3:.2f}  Acc={acc:.3f}  TPR={tpr:.3f}  FPR={fpr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657f7ff-0d5c-42b8-9159-30ae95c53999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c66595-a5a0-4d7f-85e3-cc9da205a83e",
   "metadata": {},
   "source": [
    "### Week 39 (Part 4 - Missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ee0ab-d695-41e3-8db9-cd736571b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f7b61-fa33-4eb4-b78c-e979eda280fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1a604-0b0f-42e5-85f5-1b92e8fda36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b84cbdb6-00f6-4b4e-8d9c-fe3887d74b6d",
   "metadata": {},
   "source": [
    "### Week 40 (Part 5 - Missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe5711-67d5-40a3-88d8-49628ae2cc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9a858-bb4c-4c79-9342-925d363b6f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f33196-0557-4d87-b7d3-29aec79a9990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27113c-21f7-4c3f-95f2-7a2973b46bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
